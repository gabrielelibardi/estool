{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cma\n",
    "from es import SimpleGA, CMAES, PEPG, OpenES\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    z = 1/(1 + np.exp(-x)) \n",
    "    return z\n",
    "\n",
    "def BCE_loss(y,p):\n",
    "    return np.sum(-y*np.log(p) - (1 - y)*np.log(1 - p))\n",
    "\n",
    "\n",
    "class gate_layer():\n",
    "    def __init__(self,dims, n_channels= 1, AND_OR = 1):\n",
    "        \n",
    "        # AND_OR = TRUE  : it is an AND gate\n",
    "        # AND_OR = FALSE : it is an OR gate\n",
    "        \n",
    "        self.AND_OR = AND_OR\n",
    "        self.n_channels = n_channels\n",
    "        dims[0] = n_channels\n",
    "        self.w =  np.random.normal(-3, 1, dims)\n",
    "  \n",
    "    def forward(self, X):\n",
    "       \n",
    "        X = np.repeat(X, self.n_channels, axis=0)\n",
    "\n",
    "        m = sigmoid(self.w)\n",
    "\n",
    "        if self.AND_OR == 1:\n",
    "            filtered_X = 1 - m *(1 - X) \n",
    "            \n",
    "            return np.prod(filtered_X,1)[np.newaxis,...]\n",
    "        \n",
    "        if self.AND_OR == 2:\n",
    "\n",
    "            filtered_X = m*X\n",
    "           \n",
    "            return (1- np.prod(1 - filtered_X,1))[np.newaxis,...]\n",
    "        \n",
    "        if self.AND_OR == 3:\n",
    "            # inverter\n",
    "            filtered_X = m*X\n",
    "            res = ones - filtered_X\n",
    "\n",
    "            return res\n",
    "            \n",
    "    \n",
    "class Model():\n",
    "    \n",
    "    def __init__(self, n_pop= 5000, cutoff = 5000):\n",
    "        \n",
    "        self.layers = []\n",
    "        self.n_pop = n_pop\n",
    "        self.cutoff = cutoff\n",
    "        \n",
    "    def add_layer(self,dims, n_channels, AND_OR=True, head = False):\n",
    "        # add output size arg\n",
    "        \n",
    "        lyr = gate_layer(dims, n_channels=n_channels, AND_OR=AND_OR, head=head, pop_n = self.n_pop)\n",
    "        self.layers.append(lyr)\n",
    "\n",
    "        \n",
    "    def forward(self,x, h, c):\n",
    "        inv_x = np.ones(x.shape).to(device) - x\n",
    "        aug_x = np.concatenate([x, inv_x], axis=2)\n",
    "        \n",
    "        inv_h = np.ones(h.shape).to(device) - x\n",
    "        aug_h = np.concatenate([h, inv_h], axis=2)\n",
    "\n",
    "        \n",
    "        #print(h_[0,3,:])\n",
    "        \n",
    "        xh = np.concatenate([aug_x,aug_h], axis=2)\n",
    "\n",
    "        \n",
    "        xh = self.layers[0].forward(xh)\n",
    "        xh = self.layers[1].forward(xh)\n",
    "        \n",
    "        \n",
    "        i, g, f, o = torch.split(xh,4,axis=2)\n",
    "       \n",
    "        \n",
    "        # g is old c??\n",
    "        \n",
    "        #new_c = 1 - (1 - (c * f))*(1-(g* i))\n",
    "        new_c = c*f + (1 -f)*i \n",
    "        new_h = new_c*o\n",
    "        \n",
    "        # END LSTM\n",
    "        \n",
    "        out = self.layers[2].forward(new_h)\n",
    "        Y_ = self.layers[3].forward(out)\n",
    "        \n",
    "        return new_h, new_c, Y_\n",
    "    \n",
    "\n",
    "    \n",
    "    def params(self):\n",
    "        # returns a list of the parameters to give to the optimizer\n",
    "        self.para = []\n",
    "\n",
    "        for layer in self.layers:\n",
    "        \n",
    "            self.para.append(layer.w)\n",
    "            \n",
    "        return self.para\n",
    "    \n",
    "\n",
    "            \n",
    "        \n",
    "    \n",
    "def recurrency_label(seq_len):\n",
    "    \n",
    "    labels = []\n",
    "    X = []\n",
    "\n",
    "    X = np.zeros([seq_len,1])\n",
    "    #X[0,:] = 1.0\n",
    "    for ii in range(seq_len):\n",
    "        \n",
    "        if ii % 7 == 0:\n",
    "            labels.append(np.ones([1,1]))\n",
    "\n",
    "        else:\n",
    "            labels.append(np.zeros([1,1]))\n",
    "\n",
    "    \n",
    "    return X, np.concatenate(labels, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "def evluate_func(model, params):\n",
    "    model.set_model_params(params)\n",
    "    loss_cum = 0\n",
    "    Xs, labels  = recurrency_label(10)\n",
    "    \n",
    "#     X = np.ones([1,1])\n",
    "#     inv_X = 1 - X\n",
    "\n",
    "#     aug_X = np.concatenate([X, inv_X], axis=1)\n",
    "    h_ = np.zeros([1,15])\n",
    "    c_ = np.zeros([1,15])\n",
    "\n",
    "    h_[0,0] = 1.0\n",
    "#     xh = np.concatenate([aug_X,h_], axis=1)\n",
    "#     _, h_ = model.forward(xh)\n",
    "\n",
    "    for X, label in zip(Xs,labels):\n",
    "        \n",
    "        inv_X = 1- X\n",
    "        \n",
    "        aug_X = np.concatenate([X, inv_X], axis=0)\n",
    "        \n",
    "        xh = np.concatenate([aug_X[np.newaxis,...],h_], axis=1)\n",
    "\n",
    "        h, c_, Y_= LSTM.forward(x, h, c_)\n",
    "        \n",
    "        pred = out[:,0:1]\n",
    "        h_ = np.copy(out[:,1:])\n",
    "\n",
    "        #print(label, pred)\n",
    "        loss = BCE_loss(label, pred)\n",
    "        loss_cum += loss\n",
    "    \n",
    "    return loss_cum\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.add_layer([1,12], n_channels = 20, AND_OR=1)\n",
    "model.add_layer([1,20], n_channels = 11, AND_OR=2)\n",
    "\n",
    "\n",
    "\n",
    "NPARAMS = model.num_params()       # make this a 100-dimensinal problem.\n",
    "NPOPULATION = 4001    # use population size of 101.\n",
    "MAX_ITERATION = 4000 # run each solver for 5000 generations.\n",
    "\n",
    "\n",
    "# defines genetic algorithm solver\n",
    "ga = SimpleGA(NPARAMS,                # number of model parameters\n",
    "               sigma_init=0.5,        # initial standard deviation\n",
    "               popsize=NPOPULATION,   # population size\n",
    "               elite_ratio=0.1,       # percentage of the elites\n",
    "               forget_best=False,     # forget the historical best elites\n",
    "               weight_decay=0.00,     # weight decay coefficient\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness at iteration 10 -4.462822386833646\n",
      "fitness at iteration 20 -3.3065513451317226\n",
      "fitness at iteration 30 -3.1501175078464603\n",
      "fitness at iteration 40 -3.1421075809817207\n",
      "fitness at iteration 50 -3.1403314944283\n",
      "fitness at iteration 60 -3.1397929068568153\n",
      "fitness at iteration 70 -3.139691430875459\n",
      "fitness at iteration 80 -3.1340175693868324\n",
      "fitness at iteration 90 -3.1340175693868324\n",
      "fitness at iteration 100 -3.119667619131666\n",
      "fitness at iteration 110 -3.1098642655126687\n",
      "fitness at iteration 120 -3.024168257310381\n",
      "fitness at iteration 130 -2.736313282549559\n",
      "fitness at iteration 140 -2.605895608335072\n",
      "fitness at iteration 150 -2.5257316140565558\n",
      "fitness at iteration 160 -2.4748101425168483\n",
      "fitness at iteration 170 -2.305589308138394\n",
      "fitness at iteration 180 -2.1729544872511397\n",
      "fitness at iteration 190 -2.1198930876590776\n",
      "fitness at iteration 200 -2.079013778703995\n",
      "fitness at iteration 210 -2.051618316005446\n",
      "fitness at iteration 220 -2.041695708759208\n",
      "fitness at iteration 230 -2.036802141450648\n",
      "fitness at iteration 240 -2.0313126884994355\n",
      "fitness at iteration 250 -2.0307131611688667\n",
      "fitness at iteration 260 -2.0294424929782653\n",
      "fitness at iteration 270 -2.0289739646827147\n",
      "fitness at iteration 280 -2.0283666917545986\n",
      "fitness at iteration 290 -2.0277497325625933\n",
      "fitness at iteration 300 -2.0275168725445876\n",
      "fitness at iteration 310 -2.0266618997200285\n",
      "fitness at iteration 320 -2.0266618997200285\n",
      "fitness at iteration 330 -2.026010331089861\n",
      "fitness at iteration 340 -2.026010331089861\n",
      "fitness at iteration 350 -2.0259001402449135\n",
      "fitness at iteration 360 -2.0259001402449135\n",
      "fitness at iteration 370 -2.025829252570547\n",
      "fitness at iteration 380 -2.025511550064545\n",
      "fitness at iteration 390 -2.025410190067266\n",
      "fitness at iteration 400 -2.025410190067266\n",
      "fitness at iteration 410 -2.025410190067266\n",
      "fitness at iteration 420 -2.025348606043875\n",
      "fitness at iteration 430 -2.0251124525171056\n",
      "fitness at iteration 440 -2.0251124525171056\n",
      "fitness at iteration 450 -2.0250792700980194\n",
      "fitness at iteration 460 -2.0249129449704273\n",
      "fitness at iteration 470 -2.024885196114238\n",
      "fitness at iteration 480 -2.024885196114238\n",
      "fitness at iteration 490 -2.024885196114238\n",
      "fitness at iteration 500 -2.0247423684068755\n",
      "fitness at iteration 510 -2.0247423684068755\n",
      "fitness at iteration 520 -2.0247423684068755\n",
      "fitness at iteration 530 -2.0247423684068755\n",
      "fitness at iteration 540 -2.024737814577433\n",
      "fitness at iteration 550 -2.0247005853210585\n",
      "fitness at iteration 560 -2.024638233859721\n",
      "fitness at iteration 570 -2.024638233859721\n",
      "fitness at iteration 580 -2.024638233859721\n",
      "fitness at iteration 590 -2.0245759941321033\n",
      "fitness at iteration 600 -2.0235262561039233\n",
      "fitness at iteration 610 -2.0235262561039233\n",
      "fitness at iteration 620 -2.022846394019644\n",
      "fitness at iteration 630 -2.022846394019644\n",
      "fitness at iteration 640 -2.021749035524515\n",
      "fitness at iteration 650 -2.017821650667037\n",
      "fitness at iteration 660 -2.009741997275032\n",
      "fitness at iteration 670 -1.9970628450474854\n",
      "fitness at iteration 680 -1.9878035130936946\n",
      "fitness at iteration 690 -1.9833554931930721\n",
      "fitness at iteration 700 -1.9816463439125647\n",
      "fitness at iteration 710 -1.9804943921692648\n",
      "fitness at iteration 720 -1.9800338895750422\n",
      "fitness at iteration 730 -1.9797028686819018\n",
      "fitness at iteration 740 -1.979438685647471\n",
      "fitness at iteration 750 -1.9791527966007543\n",
      "fitness at iteration 760 -1.9790313911690105\n",
      "fitness at iteration 770 -1.978970599676333\n",
      "fitness at iteration 780 -1.9789156263128755\n",
      "fitness at iteration 790 -1.9788604271151997\n",
      "fitness at iteration 800 -1.9787496815127026\n",
      "fitness at iteration 810 -1.978692417243173\n",
      "fitness at iteration 820 -1.978680009224855\n",
      "fitness at iteration 830 -1.9785982189750608\n",
      "fitness at iteration 840 -1.9785806626101137\n",
      "fitness at iteration 850 -1.9785806626101137\n",
      "fitness at iteration 860 -1.978516228879399\n",
      "fitness at iteration 870 -1.978516228879399\n",
      "fitness at iteration 880 -1.978516228879399\n",
      "fitness at iteration 890 -1.9784894326447187\n",
      "fitness at iteration 900 -1.9784894326447187\n",
      "fitness at iteration 910 -1.9784251591554365\n",
      "fitness at iteration 920 -1.9784251591554365\n",
      "fitness at iteration 930 -1.9784251591554365\n",
      "fitness at iteration 940 -1.978413785034828\n",
      "fitness at iteration 950 -1.978413785034828\n",
      "fitness at iteration 960 -1.9783916799523553\n",
      "fitness at iteration 970 -1.9783916799523553\n",
      "fitness at iteration 980 -1.978330928098301\n",
      "fitness at iteration 990 -1.978330928098301\n",
      "fitness at iteration 1000 -1.978330928098301\n",
      "fitness at iteration 1010 -1.978330928098301\n",
      "fitness at iteration 1020 -1.9783266253628777\n",
      "fitness at iteration 1030 -1.9783266253628777\n",
      "fitness at iteration 1040 -1.9783266253628777\n",
      "fitness at iteration 1050 -1.9783109941420247\n",
      "fitness at iteration 1060 -1.9783109941420247\n",
      "fitness at iteration 1070 -1.9783109941420247\n",
      "fitness at iteration 1080 -1.9782827550678426\n",
      "fitness at iteration 1090 -1.9782827550678426\n",
      "fitness at iteration 1100 -1.9782827550678426\n",
      "fitness at iteration 1110 -1.9782561957055145\n",
      "fitness at iteration 1120 -1.9782561957055145\n",
      "fitness at iteration 1130 -1.9782561957055145\n",
      "fitness at iteration 1140 -1.9782561957055145\n",
      "fitness at iteration 1150 -1.9782399686760037\n",
      "fitness at iteration 1160 -1.9782142813522137\n",
      "fitness at iteration 1170 -1.9782142813522137\n",
      "fitness at iteration 1180 -1.9782142813522137\n",
      "fitness at iteration 1190 -1.9782042640643547\n",
      "fitness at iteration 1200 -1.9782042640643547\n",
      "fitness at iteration 1210 -1.9782042640643547\n",
      "fitness at iteration 1220 -1.9781937785674686\n",
      "fitness at iteration 1230 -1.9781937785674686\n",
      "fitness at iteration 1240 -1.9781937785674686\n",
      "fitness at iteration 1250 -1.9781937785674686\n",
      "fitness at iteration 1260 -1.9781937785674686\n",
      "fitness at iteration 1270 -1.9781937785674686\n",
      "fitness at iteration 1280 -1.9781842892979733\n",
      "fitness at iteration 1290 -1.978180559313217\n",
      "fitness at iteration 1300 -1.978180559313217\n",
      "fitness at iteration 1310 -1.9781720112453693\n",
      "fitness at iteration 1320 -1.9781687301399646\n",
      "fitness at iteration 1330 -1.9781582071522517\n",
      "fitness at iteration 1340 -1.9781582071522517\n",
      "fitness at iteration 1350 -1.9781533910300606\n",
      "fitness at iteration 1360 -1.9781533910300606\n",
      "fitness at iteration 1370 -1.9781533910300606\n",
      "fitness at iteration 1380 -1.9781533910300606\n",
      "fitness at iteration 1390 -1.9781533910300606\n",
      "fitness at iteration 1400 -1.9781508226502116\n",
      "fitness at iteration 1410 -1.9781508226502116\n",
      "fitness at iteration 1420 -1.978141316955453\n",
      "fitness at iteration 1430 -1.978141316955453\n",
      "fitness at iteration 1440 -1.978141316955453\n",
      "fitness at iteration 1450 -1.9781355977596442\n",
      "fitness at iteration 1460 -1.9781355977596442\n",
      "fitness at iteration 1470 -1.978131914402166\n",
      "fitness at iteration 1480 -1.978131914402166\n",
      "fitness at iteration 1490 -1.9781306425148648\n",
      "fitness at iteration 1500 -1.9781274757805087\n",
      "fitness at iteration 1510 -1.9781274757805087\n",
      "fitness at iteration 1520 -1.9781274757805087\n",
      "fitness at iteration 1530 -1.978118633042483\n",
      "fitness at iteration 1540 -1.978114926739468\n",
      "fitness at iteration 1550 -1.978114926739468\n",
      "fitness at iteration 1560 -1.978114926739468\n",
      "fitness at iteration 1570 -1.978114926739468\n",
      "fitness at iteration 1580 -1.978114926739468\n",
      "fitness at iteration 1590 -1.978114926739468\n",
      "fitness at iteration 1600 -1.9781107339604904\n",
      "fitness at iteration 1610 -1.9781107339604904\n",
      "fitness at iteration 1620 -1.9781089211993605\n",
      "fitness at iteration 1630 -1.9781089211993605\n",
      "fitness at iteration 1640 -1.9781089211993605\n",
      "fitness at iteration 1650 -1.9781089211993605\n",
      "fitness at iteration 1660 -1.978106731016238\n",
      "fitness at iteration 1670 -1.978106731016238\n",
      "fitness at iteration 1680 -1.978106731016238\n",
      "fitness at iteration 1690 -1.9781060767395724\n",
      "fitness at iteration 1700 -1.978101811050646\n",
      "fitness at iteration 1710 -1.9780961459425024\n",
      "fitness at iteration 1720 -1.9780961459425024\n",
      "fitness at iteration 1730 -1.9780961324340736\n",
      "fitness at iteration 1740 -1.9780961324340736\n",
      "fitness at iteration 1750 -1.9780961324340736\n",
      "fitness at iteration 1760 -1.9780915019188487\n",
      "fitness at iteration 1770 -1.978089111999136\n",
      "fitness at iteration 1780 -1.978089111999136\n",
      "fitness at iteration 1790 -1.978089111999136\n",
      "fitness at iteration 1800 -1.978089111999136\n",
      "fitness at iteration 1810 -1.978089111999136\n",
      "fitness at iteration 1820 -1.978089111999136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness at iteration 1830 -1.978089111999136\n",
      "fitness at iteration 1840 -1.978089111999136\n",
      "fitness at iteration 1850 -1.978089111999136\n",
      "fitness at iteration 1860 -1.9780882787301526\n",
      "fitness at iteration 1870 -1.9780877130218226\n",
      "fitness at iteration 1880 -1.9780857434109989\n",
      "fitness at iteration 1890 -1.9780854633913798\n",
      "fitness at iteration 1900 -1.9780846189893455\n",
      "fitness at iteration 1910 -1.9780846189893455\n",
      "fitness at iteration 1920 -1.9780800318607081\n",
      "fitness at iteration 1930 -1.9780800318607081\n",
      "fitness at iteration 1940 -1.9780800318607081\n",
      "fitness at iteration 1950 -1.9780800318607081\n",
      "fitness at iteration 1960 -1.9780800318607081\n",
      "fitness at iteration 1970 -1.9780800318607081\n",
      "fitness at iteration 1980 -1.9780764168842133\n",
      "fitness at iteration 1990 -1.9780764168842133\n",
      "fitness at iteration 2000 -1.9780764168842133\n",
      "fitness at iteration 2010 -1.9780764168842133\n",
      "fitness at iteration 2020 -1.9780764168842133\n",
      "fitness at iteration 2030 -1.9780764168842133\n",
      "fitness at iteration 2040 -1.9780758792454431\n",
      "fitness at iteration 2050 -1.9780736029756052\n",
      "fitness at iteration 2060 -1.9780736029756052\n",
      "fitness at iteration 2070 -1.9780728557375713\n",
      "fitness at iteration 2080 -1.9780728557375713\n",
      "fitness at iteration 2090 -1.9780728557375713\n",
      "fitness at iteration 2100 -1.9780728557375713\n",
      "fitness at iteration 2110 -1.9780709187303218\n",
      "fitness at iteration 2120 -1.9780709187303218\n",
      "fitness at iteration 2130 -1.9780709187303218\n",
      "fitness at iteration 2140 -1.9780709187303218\n",
      "fitness at iteration 2150 -1.9780697890471497\n",
      "fitness at iteration 2160 -1.9780692809764169\n",
      "fitness at iteration 2170 -1.9780692809764169\n",
      "fitness at iteration 2180 -1.9780692809764169\n",
      "fitness at iteration 2190 -1.9780692809764169\n",
      "fitness at iteration 2200 -1.9780692809764169\n",
      "fitness at iteration 2210 -1.9780685414115973\n",
      "fitness at iteration 2220 -1.9780682936363831\n",
      "fitness at iteration 2230 -1.9780672549238494\n",
      "fitness at iteration 2240 -1.9780672549238494\n",
      "fitness at iteration 2250 -1.9780658487786857\n",
      "fitness at iteration 2260 -1.9780652117835618\n",
      "fitness at iteration 2270 -1.9780652117835618\n",
      "fitness at iteration 2280 -1.9780652117835618\n",
      "fitness at iteration 2290 -1.9780652117835618\n",
      "fitness at iteration 2300 -1.9780652117835618\n",
      "fitness at iteration 2310 -1.9780652117835618\n",
      "fitness at iteration 2320 -1.9780652117835618\n",
      "fitness at iteration 2330 -1.9780651164838285\n",
      "fitness at iteration 2340 -1.9780645180657317\n",
      "fitness at iteration 2350 -1.97806216919667\n",
      "fitness at iteration 2360 -1.97806216919667\n",
      "fitness at iteration 2370 -1.97806216919667\n",
      "fitness at iteration 2380 -1.97806216919667\n",
      "fitness at iteration 2390 -1.97806216919667\n",
      "fitness at iteration 2400 -1.97806216919667\n",
      "fitness at iteration 2410 -1.97806216919667\n",
      "fitness at iteration 2420 -1.97806216919667\n",
      "fitness at iteration 2430 -1.978061661387063\n",
      "fitness at iteration 2440 -1.978061661387063\n",
      "fitness at iteration 2450 -1.9780605792480117\n",
      "fitness at iteration 2460 -1.9780605792480117\n",
      "fitness at iteration 2470 -1.9780605792480117\n",
      "fitness at iteration 2480 -1.9780605792480117\n",
      "fitness at iteration 2490 -1.9780602174172452\n",
      "fitness at iteration 2500 -1.9780601717245225\n",
      "fitness at iteration 2510 -1.9780601717245225\n",
      "fitness at iteration 2520 -1.9780601717245225\n",
      "fitness at iteration 2530 -1.9780601717245225\n",
      "fitness at iteration 2540 -1.9780597851914998\n",
      "fitness at iteration 2550 -1.9780590843265697\n",
      "fitness at iteration 2560 -1.9780590843265697\n",
      "fitness at iteration 2570 -1.9780582835154135\n",
      "fitness at iteration 2580 -1.9780582835154135\n",
      "fitness at iteration 2590 -1.9780582835154135\n",
      "fitness at iteration 2600 -1.9780579799937212\n",
      "fitness at iteration 2610 -1.9780574479459019\n",
      "fitness at iteration 2620 -1.9780574479459019\n",
      "fitness at iteration 2630 -1.9780574479459019\n",
      "fitness at iteration 2640 -1.9780572750907415\n",
      "fitness at iteration 2650 -1.9780572750907415\n",
      "fitness at iteration 2660 -1.978056026315624\n",
      "fitness at iteration 2670 -1.978056026315624\n",
      "fitness at iteration 2680 -1.978056026315624\n",
      "fitness at iteration 2690 -1.978056026315624\n",
      "fitness at iteration 2700 -1.978056026315624\n",
      "fitness at iteration 2710 -1.9780554597589544\n",
      "fitness at iteration 2720 -1.9780554508047468\n",
      "fitness at iteration 2730 -1.9780554508047468\n",
      "fitness at iteration 2740 -1.9780544050054245\n",
      "fitness at iteration 2750 -1.9780544050054245\n",
      "fitness at iteration 2760 -1.9780544050054245\n",
      "fitness at iteration 2770 -1.9780543853508723\n",
      "fitness at iteration 2780 -1.9780543853508723\n",
      "fitness at iteration 2790 -1.9780543853508723\n",
      "fitness at iteration 2800 -1.9780543853508723\n",
      "fitness at iteration 2810 -1.9780543853508723\n",
      "fitness at iteration 2820 -1.9780539292022687\n",
      "fitness at iteration 2830 -1.9780539292022687\n",
      "fitness at iteration 2840 -1.9780539292022687\n",
      "fitness at iteration 2850 -1.9780535024890962\n",
      "fitness at iteration 2860 -1.9780535024890962\n",
      "fitness at iteration 2870 -1.9780530355722217\n",
      "fitness at iteration 2880 -1.9780530355722217\n",
      "fitness at iteration 2890 -1.9780530355722217\n",
      "fitness at iteration 2900 -1.9780529474035746\n",
      "fitness at iteration 2910 -1.9780524583006491\n",
      "fitness at iteration 2920 -1.9780524583006491\n",
      "fitness at iteration 2930 -1.9780524583006491\n",
      "fitness at iteration 2940 -1.9780524583006491\n",
      "fitness at iteration 2950 -1.9780515663224576\n",
      "fitness at iteration 2960 -1.9780515663224576\n",
      "fitness at iteration 2970 -1.9780515663224576\n",
      "fitness at iteration 2980 -1.9780515663224576\n",
      "fitness at iteration 2990 -1.9780515663224576\n",
      "fitness at iteration 3000 -1.9780515663224576\n",
      "fitness at iteration 3010 -1.9780515663224576\n",
      "fitness at iteration 3020 -1.9780513690575168\n",
      "fitness at iteration 3030 -1.9780513690575168\n",
      "fitness at iteration 3040 -1.9780513690575168\n",
      "fitness at iteration 3050 -1.9780513690575168\n",
      "fitness at iteration 3060 -1.9780505022144044\n",
      "fitness at iteration 3070 -1.9780505022144044\n",
      "fitness at iteration 3080 -1.9780505022144044\n",
      "fitness at iteration 3090 -1.9780505022144044\n",
      "fitness at iteration 3100 -1.9780485789441085\n",
      "fitness at iteration 3110 -1.9780485789441085\n",
      "fitness at iteration 3120 -1.9780485789441085\n",
      "fitness at iteration 3130 -1.9780485789441085\n",
      "fitness at iteration 3140 -1.9780485789441085\n",
      "fitness at iteration 3150 -1.9780484987813929\n",
      "fitness at iteration 3160 -1.9780484987813929\n",
      "fitness at iteration 3170 -1.9780484987813929\n",
      "fitness at iteration 3180 -1.9780484987813929\n",
      "fitness at iteration 3190 -1.9780484987813929\n",
      "fitness at iteration 3200 -1.9780484114818466\n",
      "fitness at iteration 3210 -1.978047295355298\n",
      "fitness at iteration 3220 -1.978047295355298\n",
      "fitness at iteration 3230 -1.978047295355298\n",
      "fitness at iteration 3240 -1.9780468919118401\n",
      "fitness at iteration 3250 -1.9780468919118401\n",
      "fitness at iteration 3260 -1.9780468919118401\n",
      "fitness at iteration 3270 -1.9780468919118401\n",
      "fitness at iteration 3280 -1.9780454921287292\n",
      "fitness at iteration 3290 -1.9780448180308712\n",
      "fitness at iteration 3300 -1.9780445727621703\n",
      "fitness at iteration 3310 -1.9780445727621703\n",
      "fitness at iteration 3320 -1.9780431517974928\n",
      "fitness at iteration 3330 -1.9780426502405457\n",
      "fitness at iteration 3340 -1.9780426502405457\n",
      "fitness at iteration 3350 -1.9780412831505692\n",
      "fitness at iteration 3360 -1.9780397203832574\n",
      "fitness at iteration 3370 -1.9780390211450942\n",
      "fitness at iteration 3380 -1.978036777839114\n",
      "fitness at iteration 3390 -1.9780353055090436\n",
      "fitness at iteration 3400 -1.9780349182595258\n",
      "fitness at iteration 3410 -1.9780322219512352\n",
      "fitness at iteration 3420 -1.9780322219512352\n",
      "fitness at iteration 3430 -1.9780313967197758\n",
      "fitness at iteration 3440 -1.9780274143865224\n",
      "fitness at iteration 3450 -1.9780274143865224\n",
      "fitness at iteration 3460 -1.9780243217075861\n",
      "fitness at iteration 3470 -1.9780223464120819\n",
      "fitness at iteration 3480 -1.9780186260076227\n",
      "fitness at iteration 3490 -1.9780185803732488\n",
      "fitness at iteration 3500 -1.9780151426494974\n",
      "fitness at iteration 3510 -1.9780113787734652\n",
      "fitness at iteration 3520 -1.9780079215040434\n",
      "fitness at iteration 3530 -1.9780056974565057\n",
      "fitness at iteration 3540 -1.978001251200291\n",
      "fitness at iteration 3550 -1.9779952771106601\n",
      "fitness at iteration 3560 -1.9779863169236946\n",
      "fitness at iteration 3570 -1.977983227578218\n",
      "fitness at iteration 3580 -1.977969860635683\n",
      "fitness at iteration 3590 -1.9779606989983458\n",
      "fitness at iteration 3600 -1.9779448649886209\n",
      "fitness at iteration 3610 -1.9779268817994866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness at iteration 3620 -1.9779080046804913\n",
      "fitness at iteration 3630 -1.9778831757496538\n",
      "fitness at iteration 3640 -1.9778584727617587\n",
      "fitness at iteration 3650 -1.9778156717882107\n",
      "fitness at iteration 3660 -1.9777711836313068\n",
      "fitness at iteration 3670 -1.9777149013458444\n",
      "fitness at iteration 3680 -1.9776403847653155\n",
      "fitness at iteration 3690 -1.9775541472678084\n",
      "fitness at iteration 3700 -1.9774270875395477\n",
      "fitness at iteration 3710 -1.9772801000676068\n",
      "fitness at iteration 3720 -1.9771705758855955\n",
      "fitness at iteration 3730 -1.9769822668262813\n",
      "fitness at iteration 3740 -1.9768088893597957\n",
      "fitness at iteration 3750 -1.9766102299105373\n",
      "fitness at iteration 3760 -1.9763959068978345\n",
      "fitness at iteration 3770 -1.9761359404748386\n",
      "fitness at iteration 3780 -1.97584305881659\n",
      "fitness at iteration 3790 -1.9755330584844732\n",
      "fitness at iteration 3800 -1.9752161132429267\n",
      "fitness at iteration 3810 -1.9748313228249015\n",
      "fitness at iteration 3820 -1.97439084771635\n",
      "fitness at iteration 3830 -1.9739700317910647\n",
      "fitness at iteration 3840 -1.9734269043544512\n",
      "fitness at iteration 3850 -1.9729067284133188\n",
      "fitness at iteration 3860 -1.9723307485797674\n",
      "fitness at iteration 3870 -1.9717584505273742\n",
      "fitness at iteration 3880 -1.97113834069062\n",
      "fitness at iteration 3890 -1.9704949385902681\n",
      "fitness at iteration 3900 -1.9697506344975972\n",
      "fitness at iteration 3910 -1.9690690789339749\n",
      "fitness at iteration 3920 -1.9683287084885026\n",
      "fitness at iteration 3930 -1.9675787628884884\n",
      "fitness at iteration 3940 -1.9668481935873654\n",
      "fitness at iteration 3950 -1.966077052860758\n",
      "fitness at iteration 3960 -1.9653343853532175\n",
      "fitness at iteration 3970 -1.9645647701232793\n",
      "fitness at iteration 3980 -1.9638327148799428\n",
      "fitness at iteration 3990 -1.9631732049515813\n",
      "fitness at iteration 4000 -1.962559633204771\n",
      "local optimum discovered by solver:\n",
      " [  9.75573084   3.40321913   3.41307313   5.84912279   3.69416101\n",
      "   3.17190341   4.78278514   1.24551618   0.74330837   5.42158572\n",
      "  -3.41207168  -1.37661558  13.22937372  -7.95427996   0.28908581\n",
      "   3.46221198   3.1320836    2.43353313  -1.8548803   10.76612489\n",
      "   6.37282995   4.53224494   4.96220048   7.53406862  -1.7351485\n",
      "   0.90505928  -5.14356258  -4.61223355  -4.90560342  -4.30215639\n",
      "  -7.13629261  -3.52655624  -2.95435287  -4.74027394  -2.97819063\n",
      "   5.88694559  10.84086663  -2.75564447   6.96933669  -4.58387872\n",
      "   8.93986823  -6.253758     6.42685143  -7.57358056  -0.17571352\n",
      "   8.36718364   5.36115902  -0.81226917   8.07845334  -1.12542971\n",
      "   5.39129395   1.7851926    9.5104187   -5.56310945  -1.10050549\n",
      "  -2.76593723   2.25283941   2.71063062  -9.75639087   1.34248262\n",
      " -14.28457236  -3.35703992 -14.26173721 -13.57749729 -12.83568458\n",
      " -11.86709424   8.86819119 -12.96711493 -15.32281136 -11.75005628\n",
      " -14.17400417 -14.39906582  10.38350786  -1.22165394   3.0665404\n",
      "  -4.39913112   5.93573736   0.42550824   0.02299447  -5.455608\n",
      "   9.72295963   3.87652229   3.91623185   3.47197639 -15.01941982\n",
      "  -4.04048919 -16.42338368   9.08110409 -14.57360914 -13.5686821\n",
      " -10.8490054  -14.66520201 -13.75705276 -12.56412589 -14.82770328\n",
      " -11.13523147   6.59369711  -1.35430365   5.33283173   6.97318439\n",
      "   6.72959412   1.77079214  -2.76989698  -0.30769013   8.07522453\n",
      "  -5.83240473   5.34674026   4.67344855  11.30823897   1.00629964\n",
      "   1.01388398   6.74160338   0.99241076  -1.57726107   1.66335768\n",
      "   0.83267181  -6.67701436   5.47021496   5.94572278   3.23491565\n",
      "   9.40169674  -0.76497466   0.17918989   1.2152732    0.12647772\n",
      "  -1.04417959   0.33668782  13.14934878   1.024875     6.92001927\n",
      "   6.38727438 -10.32911246 -14.24239379  -2.31868864 -12.15460468\n",
      " -11.07061769 -13.27788895 -12.13300808 -11.45897226  -9.95724793\n",
      " -11.15881028 -11.82794649 -13.24571701   9.27788939  11.18351622\n",
      "  -4.00493474   1.52641907   1.60718208   8.27646656  11.06355714\n",
      "  10.29806593  -3.53197531   3.07582175  -0.53030624   2.03215823\n",
      "   8.16798863 -10.52985013   3.18587254 -13.98329136  11.05517517\n",
      " -13.87308864  13.01420291  11.72485348  12.77795864  11.00772558\n",
      "  14.69549735 -11.02118181  10.86518264  16.25222463   9.7763023\n",
      "   3.95815312  -1.37609527   8.03988426   1.18430809   7.96055871\n",
      "   4.68081225   5.92354938   4.39020963   8.17666153  -3.82121512\n",
      " -16.3261444   -6.45318467  17.72972468 -16.97489769 -18.3831824\n",
      " -15.57098852 -17.42230171 -20.54816984 -18.88479075 -17.12545248\n",
      " -18.01442883 -18.06694269   7.57354733  -1.72237549  10.80951798\n",
      "  -3.22240339   5.07884134  -0.797417     9.90544043  -6.25197417\n",
      "   9.69714268   5.26554013   9.01795898  -1.83942773 -13.40479039\n",
      "  -3.96492248 -15.50770654 -10.44875739 -14.28781176 -13.84352295\n",
      " -13.24747676   9.05577324 -13.6198566  -12.11787387 -16.75493353\n",
      " -15.07118232   8.67748406   3.68937152   3.27742029   7.55582496\n",
      "   2.61902959  -2.60722483   1.45311693   4.56545257  -6.10184725\n",
      "  -6.8897334    6.67535251  -2.5832621    6.97015999  -1.42877955\n",
      "   7.35373482  -3.97623138   5.49408123   3.77502828  -6.92773995\n",
      "  -4.73960326  -1.93859303   3.29092977  11.13146112   2.43110659\n",
      "  -4.11731507  -2.38131184  -9.7470236    5.4065731   -3.31950009\n",
      " -16.53222172  -0.90734642 -16.30843743   0.71364135  -8.48062176\n",
      " -11.15753217 -15.55152937   2.08472363 -16.24452161  -4.8491043\n",
      "  17.8133433   -2.3150097  -16.21736946   4.43119316   4.184719\n",
      "  -5.66433638  -3.82387857  -9.75429621 -10.35438829  -9.84165278\n",
      " -17.44295166  -4.06694842 -17.34025771  -7.31745274  -4.92774375\n",
      " -10.52655186 -14.4571859  -13.28204408  -0.73980638  -0.12908288\n",
      " -17.91297067  -4.38463713 -15.82825944  -2.81250366  -9.09539913\n",
      "  11.21790895   7.54615951   0.71052599  -2.79605442   3.85213906\n",
      "  12.31628036   1.55828308  12.23349495  -6.58516587   5.44955355\n",
      "  -0.76586615  10.45441256  -5.34195263  10.46161451  -1.08698227\n",
      " -15.12639323  -0.59918771  11.71249918  -3.75060531  -2.58255841\n",
      "  -4.00042865   7.83965923  15.98088125   5.14864955   1.88413353\n",
      "  -8.9129661  -11.66135366  -8.12424911   2.50326643   0.79607082\n",
      "  -0.3717332   -4.59332695  -1.76320862 -12.76474074  -0.21387745\n",
      " -13.49156297  -1.6815568   -9.73339912   6.75285928   1.70616023\n",
      "  -1.8754865   -0.13088299  -3.1780029    2.86280149  -1.47126542\n",
      "  12.70552862  -7.71791716  13.18965578   4.06869701  -3.53478848\n",
      "   5.93514625   9.41045795   6.63843591   9.57930831   5.87627304\n",
      "  -5.57581319   8.62112424  11.22872527   4.53154352   8.90475782\n",
      "  -1.55243554  10.29738302   7.47291244   3.90978325  -2.48784398\n",
      "  13.69861189   2.29327364  13.49538178  -2.2905012   -3.75981671\n",
      "   4.98702169  12.43550449   6.92110232   8.36560957  -3.25374448\n",
      " -10.0305742   -5.93247878  11.50001679   5.31347661  -9.35039817\n",
      "  -6.33153955   7.21327712   6.31063747  -2.11848227   5.46672751\n",
      "  12.65454463  -0.69810494  12.75585892   2.07347617  -0.60370825\n",
      "   4.50131526  10.73760045   0.31801409   7.91001942   5.64152827\n",
      " -10.92829226  -0.730129    11.57519579  -8.33565624 -15.94647996\n",
      "  -2.12988953   0.12355731  -2.64976836  -2.59796805   1.47671585\n",
      "  11.78864395  -1.08866199  10.12028128  -4.00229292   1.49707299\n",
      "   6.91005746  10.60314763  -0.3179055    8.06210301  -1.68907943\n",
      "  -1.71569442  -7.15895695  14.4530575    3.97424535  -1.78188872\n",
      "   0.67164285   0.70091527  -6.23218726   0.43639344 -11.01152422\n",
      "  13.76936386  -2.15539409  10.4932241    0.59222128 -11.70987661\n",
      "   2.21056539  12.19991239  -4.95766176   9.01385424   0.39418268\n",
      "   3.56761567   1.05835079  10.14491856  -2.09948961   2.70198966\n",
      "  -1.11389314   4.90546021   4.0073074    2.49578808  -6.24747934\n",
      "  -6.89224151   2.05590667  -8.06175322   2.1330683   -2.68356118\n",
      "   2.35360863  -5.16967925  -4.05135491 -13.70911019   2.66404049\n",
      " -10.37827513  -0.95245303  -6.43218565   3.8415844   -5.57081258\n",
      "   0.85850295  -8.04108879   2.89523045   1.32194033  -7.56346454\n",
      "  12.22373874   2.23525059  12.45289524   4.07574826   3.12255163\n",
      "  -0.83593556  11.37344489  -5.70003409  13.29278338 -11.18558107\n",
      "  -9.83315011  -7.64276378  15.95522684   5.62315196   7.94746565]\n",
      "fitness score at this local optimum: -1.962559633204771\n"
     ]
    }
   ],
   "source": [
    "fit_func = evluate_func\n",
    "# defines a function to use solver to solve fit_func\n",
    "def test_solver(solver):\n",
    "    history = []\n",
    "    for j in range(MAX_ITERATION):\n",
    "        solutions = solver.ask()\n",
    "        fitness_list = np.zeros(solver.popsize)\n",
    "        #print(solutions)\n",
    "        for i in range(solver.popsize):\n",
    "            fitness_list[i] = -fit_func(model,solutions[i])\n",
    "            #print(fit_func(model,solutions[i]))\n",
    "            \n",
    "\n",
    "        solver.tell(fitness_list)\n",
    "        result = solver.result() # first element is the best solution, second element is the best fitness\n",
    "        history.append(result[1])\n",
    "        if (j+1) % 10 == 0:\n",
    "            print(\"fitness at iteration\", (j+1), result[1])\n",
    "    print(\"local optimum discovered by solver:\\n\", result[0])\n",
    "    print(\"fitness score at this local optimum:\", result[1])\n",
    "    return history\n",
    "\n",
    "ga_history = test_solver(ga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000_w,4000)-aCMA-ES (mu_w=1006.8,w_1=0%) in dimension 460 (seed=103839, Wed Jul 29 20:56:18 2020)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8d9d72de69d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0msigma_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcma_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmaes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-789ff9935242>\u001b[0m in \u001b[0;36mtest_solver\u001b[0;34m(solver)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_ITERATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0msolutions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mfitness_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#print(solutions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace7/Unity3D/gabriele/Animal-AI/ARC/estool/es.py\u001b[0m in \u001b[0;36mask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m'''returns a list of parameters'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cmaes = CMAES(NPARAMS,\n",
    "              popsize=NPOPULATION,\n",
    "              weight_decay=0.0,\n",
    "              sigma_init = 0.5\n",
    "          )\n",
    "cma_history = test_solver(cmaes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness at iteration 10 -5.060351721810443\n",
      "fitness at iteration 20 -5.039915157148965\n",
      "fitness at iteration 30 -5.039915157148965\n",
      "fitness at iteration 40 -4.786325644061899\n",
      "fitness at iteration 50 -4.542477245908696\n",
      "fitness at iteration 60 -4.429039767539853\n",
      "fitness at iteration 70 -4.251950382815559\n",
      "fitness at iteration 80 -4.0853189386801185\n",
      "fitness at iteration 90 -3.9931903311926185\n",
      "fitness at iteration 100 -3.920931923563131\n",
      "fitness at iteration 110 -3.8404116734408658\n",
      "fitness at iteration 120 -3.7180221391675548\n",
      "fitness at iteration 130 -3.638605300471249\n",
      "fitness at iteration 140 -3.552462794918037\n",
      "fitness at iteration 150 -3.4683311834682544\n",
      "fitness at iteration 160 -3.4211360793875167\n",
      "fitness at iteration 170 -3.380197272642628\n",
      "fitness at iteration 180 -3.3586081468875624\n",
      "fitness at iteration 190 -3.3193830277422918\n",
      "fitness at iteration 200 -3.2854970680712694\n",
      "fitness at iteration 210 -3.2587221839715754\n",
      "fitness at iteration 220 -3.242087785954948\n",
      "fitness at iteration 230 -3.2322815547202497\n",
      "fitness at iteration 240 -3.223296964538718\n",
      "fitness at iteration 250 -3.216082771253576\n",
      "fitness at iteration 260 -3.205100297297819\n",
      "fitness at iteration 270 -3.1982464676443096\n",
      "fitness at iteration 280 -3.194766811874766\n",
      "fitness at iteration 290 -3.1868281730288577\n",
      "fitness at iteration 300 -3.180086406289786\n",
      "fitness at iteration 310 -3.177294883750995\n",
      "fitness at iteration 320 -3.1714597094651826\n",
      "fitness at iteration 330 -3.1689955794117846\n",
      "fitness at iteration 340 -3.168333999775288\n",
      "fitness at iteration 350 -3.1665410555109625\n",
      "fitness at iteration 360 -3.1638605235819575\n",
      "fitness at iteration 370 -3.1638605235819575\n",
      "fitness at iteration 380 -3.162694449486774\n",
      "fitness at iteration 390 -3.162694449486774\n",
      "fitness at iteration 400 -3.1625223952765693\n",
      "fitness at iteration 410 -3.1617881677244912\n",
      "fitness at iteration 420 -3.160398217823558\n",
      "fitness at iteration 430 -3.1585439635445254\n",
      "fitness at iteration 440 -3.156857494503659\n",
      "fitness at iteration 450 -3.1556290887628253\n",
      "fitness at iteration 460 -3.155038023857966\n",
      "fitness at iteration 470 -3.153561761712357\n",
      "fitness at iteration 480 -3.1526115554679417\n",
      "fitness at iteration 490 -3.152415331316435\n",
      "fitness at iteration 500 -3.151206501381537\n",
      "fitness at iteration 510 -3.1510687173699203\n",
      "fitness at iteration 520 -3.150806276477243\n",
      "fitness at iteration 530 -3.150437616206999\n",
      "fitness at iteration 540 -3.150142026461554\n",
      "fitness at iteration 550 -3.150030552120076\n",
      "fitness at iteration 560 -3.150030552120076\n",
      "fitness at iteration 570 -3.150030552120076\n",
      "fitness at iteration 580 -3.149912726573014\n",
      "fitness at iteration 590 -3.1498420446930138\n",
      "fitness at iteration 600 -3.1498420446930138\n",
      "fitness at iteration 610 -3.149698145553998\n",
      "fitness at iteration 620 -3.149698145553998\n",
      "fitness at iteration 630 -3.149698145553998\n",
      "fitness at iteration 640 -3.149698145553998\n",
      "fitness at iteration 650 -3.149698145553998\n",
      "fitness at iteration 660 -3.149698145553998\n",
      "fitness at iteration 670 -3.149698145553998\n",
      "fitness at iteration 680 -3.149569225257744\n",
      "fitness at iteration 690 -3.149569225257744\n",
      "fitness at iteration 700 -3.1495637704885033\n",
      "fitness at iteration 710 -3.149472546872231\n",
      "fitness at iteration 720 -3.149472546872231\n",
      "fitness at iteration 730 -3.149151482448712\n",
      "fitness at iteration 740 -3.1489782759750007\n",
      "fitness at iteration 750 -3.1489782759750007\n",
      "fitness at iteration 760 -3.1489782759750007\n",
      "fitness at iteration 770 -3.1489057041744157\n",
      "fitness at iteration 780 -3.1487553875120478\n",
      "fitness at iteration 790 -3.1486587978889484\n",
      "fitness at iteration 800 -3.1486147235177593\n",
      "fitness at iteration 810 -3.148295815298394\n",
      "fitness at iteration 820 -3.148295815298394\n",
      "fitness at iteration 830 -3.148295815298394\n",
      "fitness at iteration 840 -3.1482040938913713\n",
      "fitness at iteration 850 -3.1482040938913713\n",
      "fitness at iteration 860 -3.1481075321985674\n",
      "fitness at iteration 870 -3.14807774655413\n",
      "fitness at iteration 880 -3.1479399549831046\n",
      "fitness at iteration 890 -3.1479399549831046\n",
      "fitness at iteration 900 -3.1479399549831046\n",
      "fitness at iteration 910 -3.1478391186580286\n",
      "fitness at iteration 920 -3.1478391186580286\n",
      "fitness at iteration 930 -3.1477728761853543\n",
      "fitness at iteration 940 -3.1477728761853543\n",
      "fitness at iteration 950 -3.1477728761853543\n",
      "fitness at iteration 960 -3.1477728761853543\n",
      "fitness at iteration 970 -3.1477728761853543\n",
      "fitness at iteration 980 -3.1477362444176604\n",
      "fitness at iteration 990 -3.1477362444176604\n",
      "fitness at iteration 1000 -3.1477362444176604\n",
      "fitness at iteration 1010 -3.147682592801772\n",
      "fitness at iteration 1020 -3.1476163202076557\n",
      "fitness at iteration 1030 -3.1476163202076557\n",
      "fitness at iteration 1040 -3.1475915106870356\n",
      "fitness at iteration 1050 -3.1475915106870356\n",
      "fitness at iteration 1060 -3.1475915106870356\n",
      "fitness at iteration 1070 -3.1474677452000632\n",
      "fitness at iteration 1080 -3.1474677452000632\n",
      "fitness at iteration 1090 -3.1474677452000632\n",
      "fitness at iteration 1100 -3.1474677452000632\n",
      "fitness at iteration 1110 -3.1473743125857023\n",
      "fitness at iteration 1120 -3.1473743125857023\n",
      "fitness at iteration 1130 -3.1473743125857023\n",
      "fitness at iteration 1140 -3.1473743125857023\n",
      "fitness at iteration 1150 -3.1473743125857023\n",
      "fitness at iteration 1160 -3.1473743125857023\n",
      "fitness at iteration 1170 -3.1473743125857023\n",
      "fitness at iteration 1180 -3.1473743125857023\n",
      "fitness at iteration 1190 -3.1473743125857023\n",
      "fitness at iteration 1200 -3.1473743125857023\n",
      "fitness at iteration 1210 -3.1473743125857023\n",
      "fitness at iteration 1220 -3.1473743125857023\n",
      "fitness at iteration 1230 -3.1473743125857023\n",
      "fitness at iteration 1240 -3.1473743125857023\n",
      "fitness at iteration 1250 -3.1473743125857023\n",
      "fitness at iteration 1260 -3.1473743125857023\n",
      "fitness at iteration 1270 -3.1473743125857023\n",
      "fitness at iteration 1280 -3.1473743125857023\n",
      "fitness at iteration 1290 -3.1473743125857023\n",
      "fitness at iteration 1300 -3.1473743125857023\n",
      "fitness at iteration 1310 -3.1473743125857023\n",
      "fitness at iteration 1320 -3.1473743125857023\n",
      "fitness at iteration 1330 -3.1473743125857023\n",
      "fitness at iteration 1340 -3.1473743125857023\n",
      "fitness at iteration 1350 -3.1473743125857023\n",
      "fitness at iteration 1360 -3.1473743125857023\n",
      "fitness at iteration 1370 -3.1473743125857023\n",
      "fitness at iteration 1380 -3.1473743125857023\n",
      "fitness at iteration 1390 -3.1473743125857023\n",
      "fitness at iteration 1400 -3.1473743125857023\n",
      "fitness at iteration 1410 -3.1473743125857023\n",
      "fitness at iteration 1420 -3.1473743125857023\n",
      "fitness at iteration 1430 -3.1473743125857023\n",
      "fitness at iteration 1440 -3.1473743125857023\n",
      "fitness at iteration 1450 -3.1473743125857023\n",
      "fitness at iteration 1460 -3.1473743125857023\n",
      "fitness at iteration 1470 -3.1473743125857023\n",
      "fitness at iteration 1480 -3.1473743125857023\n",
      "fitness at iteration 1490 -3.1473743125857023\n",
      "fitness at iteration 1500 -3.1473743125857023\n",
      "fitness at iteration 1510 -3.1473743125857023\n",
      "fitness at iteration 1520 -3.1473743125857023\n",
      "fitness at iteration 1530 -3.1473743125857023\n",
      "fitness at iteration 1540 -3.1473743125857023\n",
      "fitness at iteration 1550 -3.1473743125857023\n",
      "fitness at iteration 1560 -3.1473743125857023\n",
      "fitness at iteration 1570 -3.1473743125857023\n",
      "fitness at iteration 1580 -3.1473743125857023\n",
      "fitness at iteration 1590 -3.1473743125857023\n",
      "fitness at iteration 1600 -3.1473743125857023\n",
      "fitness at iteration 1610 -3.1473743125857023\n",
      "fitness at iteration 1620 -3.1473743125857023\n",
      "fitness at iteration 1630 -3.1473743125857023\n",
      "fitness at iteration 1640 -3.1473743125857023\n",
      "fitness at iteration 1650 -3.1473743125857023\n",
      "fitness at iteration 1660 -3.1473743125857023\n",
      "fitness at iteration 1670 -3.1473743125857023\n",
      "fitness at iteration 1680 -3.1473743125857023\n",
      "fitness at iteration 1690 -3.1473743125857023\n",
      "fitness at iteration 1700 -3.1473743125857023\n",
      "fitness at iteration 1710 -3.1473743125857023\n",
      "fitness at iteration 1720 -3.1473743125857023\n",
      "fitness at iteration 1730 -3.1473743125857023\n",
      "fitness at iteration 1740 -3.1473743125857023\n",
      "fitness at iteration 1750 -3.1473743125857023\n",
      "fitness at iteration 1760 -3.1473743125857023\n",
      "fitness at iteration 1770 -3.1473743125857023\n",
      "fitness at iteration 1780 -3.1473743125857023\n",
      "fitness at iteration 1790 -3.1473743125857023\n",
      "fitness at iteration 1800 -3.1473743125857023\n",
      "fitness at iteration 1810 -3.1473743125857023\n",
      "fitness at iteration 1820 -3.1473743125857023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness at iteration 1830 -3.1473743125857023\n",
      "fitness at iteration 1840 -3.1473743125857023\n",
      "fitness at iteration 1850 -3.1473743125857023\n",
      "fitness at iteration 1860 -3.1473743125857023\n",
      "fitness at iteration 1870 -3.1473743125857023\n",
      "fitness at iteration 1880 -3.1473743125857023\n",
      "fitness at iteration 1890 -3.1473743125857023\n",
      "fitness at iteration 1900 -3.1473743125857023\n",
      "fitness at iteration 1910 -3.1473743125857023\n",
      "fitness at iteration 1920 -3.1473743125857023\n",
      "fitness at iteration 1930 -3.1473743125857023\n",
      "fitness at iteration 1940 -3.1473743125857023\n",
      "fitness at iteration 1950 -3.1473743125857023\n",
      "fitness at iteration 1960 -3.1473743125857023\n",
      "fitness at iteration 1970 -3.1473743125857023\n",
      "fitness at iteration 1980 -3.1473743125857023\n",
      "fitness at iteration 1990 -3.1473743125857023\n",
      "fitness at iteration 2000 -3.1473743125857023\n",
      "fitness at iteration 2010 -3.1473743125857023\n",
      "fitness at iteration 2020 -3.1473743125857023\n",
      "fitness at iteration 2030 -3.1473743125857023\n",
      "fitness at iteration 2040 -3.1473743125857023\n",
      "fitness at iteration 2050 -3.1473743125857023\n",
      "fitness at iteration 2060 -3.1473743125857023\n",
      "fitness at iteration 2070 -3.1473743125857023\n",
      "fitness at iteration 2080 -3.1473743125857023\n",
      "fitness at iteration 2090 -3.1473743125857023\n",
      "fitness at iteration 2100 -3.1473743125857023\n",
      "fitness at iteration 2110 -3.1473743125857023\n",
      "fitness at iteration 2120 -3.1473743125857023\n",
      "fitness at iteration 2130 -3.1473743125857023\n",
      "fitness at iteration 2140 -3.1473743125857023\n",
      "fitness at iteration 2150 -3.1473743125857023\n",
      "fitness at iteration 2160 -3.1473743125857023\n",
      "fitness at iteration 2170 -3.1473743125857023\n",
      "fitness at iteration 2180 -3.1473743125857023\n",
      "fitness at iteration 2190 -3.1473743125857023\n",
      "fitness at iteration 2200 -3.1473743125857023\n",
      "fitness at iteration 2210 -3.1473743125857023\n",
      "fitness at iteration 2220 -3.1473743125857023\n",
      "fitness at iteration 2230 -3.1473743125857023\n",
      "fitness at iteration 2240 -3.1473743125857023\n",
      "fitness at iteration 2250 -3.1473743125857023\n",
      "fitness at iteration 2260 -3.1473743125857023\n",
      "fitness at iteration 2270 -3.1473743125857023\n",
      "fitness at iteration 2280 -3.1473743125857023\n",
      "fitness at iteration 2290 -3.1473743125857023\n",
      "fitness at iteration 2300 -3.1473743125857023\n",
      "fitness at iteration 2310 -3.1473743125857023\n",
      "fitness at iteration 2320 -3.1473743125857023\n",
      "fitness at iteration 2330 -3.1473743125857023\n",
      "fitness at iteration 2340 -3.1473743125857023\n",
      "fitness at iteration 2350 -3.1473743125857023\n",
      "fitness at iteration 2360 -3.1473743125857023\n",
      "fitness at iteration 2370 -3.1473743125857023\n",
      "fitness at iteration 2380 -3.1473743125857023\n",
      "fitness at iteration 2390 -3.1473743125857023\n",
      "fitness at iteration 2400 -3.1473743125857023\n",
      "fitness at iteration 2410 -3.1473743125857023\n",
      "fitness at iteration 2420 -3.1473743125857023\n",
      "fitness at iteration 2430 -3.1473743125857023\n",
      "fitness at iteration 2440 -3.1473743125857023\n",
      "fitness at iteration 2450 -3.1473743125857023\n",
      "fitness at iteration 2460 -3.1473743125857023\n",
      "fitness at iteration 2470 -3.1473743125857023\n",
      "fitness at iteration 2480 -3.1473743125857023\n",
      "fitness at iteration 2490 -3.1473743125857023\n",
      "fitness at iteration 2500 -3.1473743125857023\n",
      "fitness at iteration 2510 -3.1473743125857023\n",
      "fitness at iteration 2520 -3.1473743125857023\n",
      "fitness at iteration 2530 -3.1473743125857023\n",
      "fitness at iteration 2540 -3.1473743125857023\n",
      "fitness at iteration 2550 -3.1473743125857023\n",
      "fitness at iteration 2560 -3.1473743125857023\n",
      "fitness at iteration 2570 -3.1473743125857023\n",
      "fitness at iteration 2580 -3.1473743125857023\n",
      "fitness at iteration 2590 -3.1473743125857023\n",
      "fitness at iteration 2600 -3.1473743125857023\n",
      "fitness at iteration 2610 -3.1473743125857023\n",
      "fitness at iteration 2620 -3.1473743125857023\n",
      "fitness at iteration 2630 -3.1473743125857023\n",
      "fitness at iteration 2640 -3.1473743125857023\n",
      "fitness at iteration 2650 -3.1473743125857023\n",
      "fitness at iteration 2660 -3.1473743125857023\n",
      "fitness at iteration 2670 -3.1473743125857023\n",
      "fitness at iteration 2680 -3.1473743125857023\n",
      "fitness at iteration 2690 -3.1473743125857023\n",
      "fitness at iteration 2700 -3.1473743125857023\n",
      "fitness at iteration 2710 -3.1473743125857023\n",
      "fitness at iteration 2720 -3.1473743125857023\n",
      "fitness at iteration 2730 -3.1473743125857023\n",
      "fitness at iteration 2740 -3.1473743125857023\n",
      "fitness at iteration 2750 -3.1473743125857023\n",
      "fitness at iteration 2760 -3.1473743125857023\n",
      "fitness at iteration 2770 -3.1473743125857023\n",
      "fitness at iteration 2780 -3.1473743125857023\n",
      "fitness at iteration 2790 -3.1473743125857023\n",
      "fitness at iteration 2800 -3.1473743125857023\n",
      "fitness at iteration 2810 -3.1473743125857023\n",
      "fitness at iteration 2820 -3.1473743125857023\n",
      "fitness at iteration 2830 -3.1473743125857023\n",
      "fitness at iteration 2840 -3.1473743125857023\n",
      "fitness at iteration 2850 -3.1473743125857023\n",
      "fitness at iteration 2860 -3.1473743125857023\n",
      "fitness at iteration 2870 -3.1473743125857023\n",
      "fitness at iteration 2880 -3.1473743125857023\n",
      "fitness at iteration 2890 -3.1473743125857023\n",
      "fitness at iteration 2900 -3.1473743125857023\n",
      "fitness at iteration 2910 -3.1473743125857023\n",
      "fitness at iteration 2920 -3.1473743125857023\n",
      "fitness at iteration 2930 -3.1473743125857023\n",
      "fitness at iteration 2940 -3.1473743125857023\n",
      "fitness at iteration 2950 -3.1473743125857023\n",
      "fitness at iteration 2960 -3.1473743125857023\n",
      "fitness at iteration 2970 -3.1473743125857023\n",
      "fitness at iteration 2980 -3.1473743125857023\n",
      "fitness at iteration 2990 -3.1473743125857023\n",
      "fitness at iteration 3000 -3.1473743125857023\n",
      "fitness at iteration 3010 -3.1473743125857023\n",
      "fitness at iteration 3020 -3.1473743125857023\n",
      "fitness at iteration 3030 -3.1473743125857023\n",
      "fitness at iteration 3040 -3.1473743125857023\n",
      "fitness at iteration 3050 -3.1473743125857023\n",
      "fitness at iteration 3060 -3.1473743125857023\n",
      "fitness at iteration 3070 -3.1473743125857023\n",
      "fitness at iteration 3080 -3.1473743125857023\n",
      "fitness at iteration 3090 -3.1473743125857023\n",
      "fitness at iteration 3100 -3.1473743125857023\n",
      "fitness at iteration 3110 -3.1473743125857023\n",
      "fitness at iteration 3120 -3.1473743125857023\n",
      "fitness at iteration 3130 -3.1473743125857023\n",
      "fitness at iteration 3140 -3.1473743125857023\n",
      "fitness at iteration 3150 -3.1473743125857023\n",
      "fitness at iteration 3160 -3.1473743125857023\n",
      "fitness at iteration 3170 -3.1473743125857023\n",
      "fitness at iteration 3180 -3.1473743125857023\n",
      "fitness at iteration 3190 -3.1473743125857023\n",
      "fitness at iteration 3200 -3.1473743125857023\n",
      "fitness at iteration 3210 -3.1473743125857023\n",
      "fitness at iteration 3220 -3.1473743125857023\n",
      "fitness at iteration 3230 -3.1473743125857023\n",
      "fitness at iteration 3240 -3.1473743125857023\n",
      "fitness at iteration 3250 -3.1473743125857023\n",
      "fitness at iteration 3260 -3.1473743125857023\n",
      "fitness at iteration 3270 -3.1473743125857023\n",
      "fitness at iteration 3280 -3.1473743125857023\n",
      "fitness at iteration 3290 -3.1473743125857023\n",
      "fitness at iteration 3300 -3.1473743125857023\n",
      "fitness at iteration 3310 -3.1473743125857023\n",
      "fitness at iteration 3320 -3.1473743125857023\n",
      "fitness at iteration 3330 -3.1473743125857023\n",
      "fitness at iteration 3340 -3.1473743125857023\n",
      "fitness at iteration 3350 -3.1473743125857023\n",
      "fitness at iteration 3360 -3.1473743125857023\n",
      "fitness at iteration 3370 -3.1473743125857023\n",
      "fitness at iteration 3380 -3.1473743125857023\n",
      "fitness at iteration 3390 -3.1473743125857023\n",
      "fitness at iteration 3400 -3.1473743125857023\n",
      "fitness at iteration 3410 -3.1473743125857023\n",
      "fitness at iteration 3420 -3.1473743125857023\n",
      "fitness at iteration 3430 -3.1473743125857023\n",
      "fitness at iteration 3440 -3.1473743125857023\n",
      "fitness at iteration 3450 -3.1473743125857023\n",
      "fitness at iteration 3460 -3.1473743125857023\n",
      "fitness at iteration 3470 -3.1473743125857023\n",
      "fitness at iteration 3480 -3.1473743125857023\n",
      "fitness at iteration 3490 -3.1473743125857023\n",
      "fitness at iteration 3500 -3.1473743125857023\n",
      "fitness at iteration 3510 -3.1473743125857023\n",
      "fitness at iteration 3520 -3.1473743125857023\n",
      "fitness at iteration 3530 -3.1473743125857023\n",
      "fitness at iteration 3540 -3.1473743125857023\n",
      "fitness at iteration 3550 -3.1473743125857023\n",
      "fitness at iteration 3560 -3.1473743125857023\n",
      "fitness at iteration 3570 -3.1473743125857023\n",
      "fitness at iteration 3580 -3.1473743125857023\n",
      "fitness at iteration 3590 -3.1473743125857023\n",
      "fitness at iteration 3600 -3.1473743125857023\n",
      "fitness at iteration 3610 -3.1473743125857023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness at iteration 3620 -3.1473743125857023\n",
      "fitness at iteration 3630 -3.1473743125857023\n",
      "fitness at iteration 3640 -3.1473743125857023\n",
      "fitness at iteration 3650 -3.1473743125857023\n",
      "fitness at iteration 3660 -3.1473743125857023\n",
      "fitness at iteration 3670 -3.1473743125857023\n",
      "fitness at iteration 3680 -3.1473743125857023\n",
      "fitness at iteration 3690 -3.1473743125857023\n",
      "fitness at iteration 3700 -3.1473743125857023\n",
      "fitness at iteration 3710 -3.1473743125857023\n",
      "fitness at iteration 3720 -3.1473743125857023\n",
      "fitness at iteration 3730 -3.1473743125857023\n",
      "fitness at iteration 3740 -3.1473743125857023\n",
      "fitness at iteration 3750 -3.1473743125857023\n",
      "fitness at iteration 3760 -3.1473743125857023\n",
      "fitness at iteration 3770 -3.1473743125857023\n",
      "fitness at iteration 3780 -3.1473743125857023\n",
      "fitness at iteration 3790 -3.1473743125857023\n",
      "fitness at iteration 3800 -3.1473743125857023\n",
      "fitness at iteration 3810 -3.1473743125857023\n",
      "fitness at iteration 3820 -3.1473743125857023\n",
      "fitness at iteration 3830 -3.1473743125857023\n",
      "fitness at iteration 3840 -3.1473743125857023\n",
      "fitness at iteration 3850 -3.1473743125857023\n",
      "fitness at iteration 3860 -3.1473743125857023\n",
      "fitness at iteration 3870 -3.1473743125857023\n",
      "fitness at iteration 3880 -3.1473743125857023\n",
      "fitness at iteration 3890 -3.1473743125857023\n",
      "fitness at iteration 3900 -3.1473743125857023\n",
      "fitness at iteration 3910 -3.1473743125857023\n",
      "fitness at iteration 3920 -3.1473743125857023\n",
      "fitness at iteration 3930 -3.1473743125857023\n",
      "fitness at iteration 3940 -3.1473743125857023\n",
      "fitness at iteration 3950 -3.1473743125857023\n",
      "fitness at iteration 3960 -3.1473743125857023\n",
      "fitness at iteration 3970 -3.1473743125857023\n",
      "fitness at iteration 3980 -3.1473743125857023\n",
      "fitness at iteration 3990 -3.1473743125857023\n",
      "fitness at iteration 4000 -3.1473743125857023\n",
      "local optimum discovered by solver:\n",
      " [ 1.58611855e+00 -2.84133778e+00  1.54509570e+00  1.77184867e-01\n",
      " -2.63893109e+00 -4.32382694e-01 -9.64783944e-01 -1.66447279e+00\n",
      "  1.07640820e-01 -1.45649965e+00  1.01200684e-01 -4.84555317e-01\n",
      "  1.89273366e-01 -1.92959756e-01  1.46657174e+00 -2.87442570e-01\n",
      "  4.55844704e-01 -1.75954759e+00 -1.72389613e+00 -3.03575399e-02\n",
      " -1.48116602e-01  2.08118587e-01 -3.38758850e-01 -5.09136077e-01\n",
      "  1.71455680e-01 -3.12639984e+00  5.41245658e+00  3.00504417e-02\n",
      " -9.99424805e-01 -8.43966507e-01 -4.23151075e+00 -8.06970230e-01\n",
      "  3.44111480e-01 -3.89656221e+00 -1.07200696e+00 -8.72276715e-01\n",
      "  1.55086752e+00 -9.78212761e-01  2.08877634e+00 -7.52348746e-01\n",
      " -1.55775500e+00 -2.94293786e-01 -6.36998202e-01 -1.08231122e+00\n",
      " -2.56845363e+00  1.69928915e-01 -1.78152892e-01 -1.02605140e+00\n",
      "  6.45432297e-01  6.70965593e-01  1.99253523e+00 -6.33874643e-01\n",
      "  6.60166852e-01 -8.27814505e-01 -1.93078143e+00  1.73999425e-01\n",
      " -5.01508464e-01 -6.03335894e-01 -1.33308335e+00  1.10983948e-01\n",
      "  1.48378476e+00  1.78477700e+00  9.22932057e-01  3.29263780e-01\n",
      "  4.27254389e-01  5.86382035e-01  6.50999143e-01  2.26006726e-01\n",
      "  4.18176085e-01  1.08365794e+00  2.17443329e-02 -1.88429688e+00\n",
      "  3.08062428e-01  3.32631033e-02  2.17078948e+00  5.36315722e-02\n",
      " -5.03214281e-01 -1.13582056e+00  8.73243689e-01 -1.02872782e+00\n",
      "  1.22988160e-01 -4.55743413e-01 -3.21660100e-01 -5.24934957e-03\n",
      "  1.14863715e+00 -6.76992318e-01  1.36950047e+00 -7.28295083e-01\n",
      "  1.64410684e-01 -4.38948527e-01  2.34064352e-01 -9.52301352e-01\n",
      " -2.96412424e+00 -1.88608106e-01 -9.29738033e-02 -2.32574349e+00\n",
      "  1.30820687e+00 -1.34877698e+00  1.31574113e+00 -1.04744678e+00\n",
      "  7.01200159e-01 -4.37771508e-01 -1.51148601e+00 -1.72000385e+00\n",
      " -4.85586241e-01  1.17717305e+00 -1.90180495e+00 -5.41740146e-01\n",
      " -2.78118273e+00  4.03836688e-01  1.93625511e+00 -4.43286950e+00\n",
      " -2.35039384e+00 -3.88814630e+00 -4.50581672e+00 -3.89880169e+00\n",
      " -3.72980199e+00 -2.46755512e+00 -3.01270877e+00 -4.22007506e+00\n",
      " -5.06677396e+00  1.17612502e+00  5.12775091e+00 -8.29718016e+00\n",
      " -7.54109355e+00 -6.61253559e+00 -7.98820519e+00 -7.14896563e+00\n",
      " -5.84875324e+00 -6.20365068e+00 -8.37513929e+00 -7.48264312e+00\n",
      "  7.00371393e-01 -1.11172615e+00  2.06614307e+00  8.12323270e-01\n",
      "  1.61149189e-02  1.59099025e-01 -5.08008429e-01 -7.39485952e-01\n",
      " -4.76334224e-01  5.47691713e-01 -1.91736482e-01 -4.74379263e-01\n",
      "  1.91599587e+00  1.66547700e+00  2.93838554e+00  1.22441774e+00\n",
      "  9.76329855e-01 -8.69393449e-01  4.23572783e-01 -1.06816625e+00\n",
      "  7.33016788e-01  1.17722214e+00 -1.94231777e+00 -7.69385596e-01\n",
      "  1.03738139e+00 -1.66386272e+00  3.23828373e+00  5.29049894e-02\n",
      " -4.97753229e-01 -1.26846229e+00 -4.11624339e-01 -8.42033688e-01\n",
      " -5.67931242e-01 -9.98002993e-03 -1.05523942e+00  1.01049555e-01\n",
      "  1.23303219e-01 -3.17695748e+00  2.30413895e+00 -2.51822507e+00\n",
      "  3.47950326e-02 -1.54220728e+00 -1.19085684e+00 -2.03645720e+00\n",
      " -2.94229625e-01 -3.81633348e-01 -1.22476405e+00 -2.09524392e+00\n",
      "  7.48019053e-02  8.35923997e-01  1.42551619e+00 -3.35162672e+00\n",
      " -1.46349141e+00 -1.28469691e+00 -9.90635568e-01 -2.20239893e+00\n",
      " -3.00844235e+00  5.45662697e-02 -2.28503273e+00 -2.18446933e+00\n",
      "  1.39421836e+00 -1.99553358e+00  3.32218920e+00 -2.99422778e+00\n",
      " -3.29725670e-02 -7.58889993e-02 -2.13954594e+00  1.30253315e-01\n",
      "  8.78832124e-01  1.21163230e+00 -2.09923694e+00  1.88380670e-01\n",
      "  8.86485679e-01 -3.85214311e+00 -4.30962122e-01  6.06025611e-01\n",
      " -1.03531876e+00  6.30763132e-02  6.31246483e-01 -1.22026755e-01\n",
      " -4.41465328e-01  1.10996139e+00  4.41338692e-01  1.25939162e-01\n",
      "  1.15040100e+00  2.65961914e-01  1.78315569e+00 -1.07075684e+00\n",
      " -1.65940821e+00 -1.24577070e+00 -3.15785993e-01 -1.84133910e+00\n",
      "  3.47869701e-01 -3.42815660e-01 -4.99532674e-01  6.75278280e-01\n",
      "  1.11088049e+00 -8.87020414e-01  1.94844458e+00 -1.71861275e+00\n",
      "  7.49128207e-01 -2.11952702e+00  5.22872861e-01  7.68217068e-01\n",
      "  6.17299176e-02  6.21628933e-01  6.03479887e-01 -1.10836931e-01\n",
      "  2.28147524e+00  6.60610268e+00  5.96531210e+00  5.51310295e+00\n",
      "  1.75486553e+00  2.44112012e+00  6.12536133e+00  2.88236642e+00\n",
      "  3.94246526e+00  6.43146499e+00  9.88685455e+00  3.98245597e+00\n",
      "  2.99439107e+00  4.88148753e+00  6.74728336e+00  5.25334850e+00\n",
      "  5.73989388e+00  2.45930141e+00  2.40655862e+00  2.35247921e+00\n",
      " -3.66096680e+00 -4.28814387e+00 -6.04192829e+00 -5.34295355e+00\n",
      " -4.10215000e+00  1.78727387e+00 -4.50474094e+00 -4.24942918e+00\n",
      " -3.92070724e+00 -9.43408547e+00 -9.77934760e+00 -3.23125716e+00\n",
      " -6.87395959e-01 -5.44291832e+00 -8.01202973e+00 -7.46004762e+00\n",
      " -3.65691052e+00 -3.24168828e+00 -3.92492093e+00 -6.56548248e-01\n",
      "  1.47858600e+00  1.24346050e-01 -4.26582113e+00 -3.20479565e+00\n",
      " -1.96010845e+00  1.64614942e+00 -8.11673159e-01  3.82816595e+00\n",
      " -5.85688774e-01 -3.60152908e+00 -6.85821281e+00 -8.92562950e-01\n",
      "  7.76866706e-01 -1.04563011e+00 -3.60879066e+00 -2.84180597e+00\n",
      " -3.49715912e+00 -2.19045727e+00 -4.22852746e+00  2.09357016e+00\n",
      " -2.37926159e+00 -2.10953755e+00 -3.29240447e+00  1.32627337e+00\n",
      " -3.21244091e+00 -1.68910943e+00  2.99524786e-01 -3.76526204e+00\n",
      " -2.16108398e+00 -4.86095256e+00 -6.39310305e+00 -3.19815711e+00\n",
      " -3.44315855e+00  4.29975584e+00 -2.28062698e+00 -2.88759096e+00\n",
      " -1.51786971e+00 -6.52977145e-01 -9.40286813e-01 -2.01768774e+00\n",
      " -2.18336783e+00 -2.95934882e+00 -4.71403064e+00 -2.98300185e+00\n",
      " -3.84101894e+00  2.16980028e+00  1.32847250e+00 -2.67095713e+00\n",
      " -3.50703744e+00 -3.61083458e+00 -6.40871435e+00 -2.60671787e+00\n",
      " -3.33767947e+00  1.67643892e+00 -4.73642352e+00 -1.60585669e+00\n",
      " -1.10527216e+00 -7.27852866e-01 -2.61425212e+00 -3.61746214e+00\n",
      " -1.99590212e+00 -3.37729910e+00 -5.32709403e-01 -1.01652770e+00\n",
      " -1.89606249e+00 -2.55100072e+00 -2.62212503e+00 -2.08227939e+00\n",
      " -3.04009600e+00 -3.73390281e+00 -5.35799748e+00 -3.11091725e+00\n",
      " -2.39660453e+00 -1.21208779e+00 -2.41561136e+00 -3.99677357e+00\n",
      " -2.24047454e-01 -2.99690197e-01 -3.52448961e+00 -3.45493009e+00\n",
      " -1.98524503e+00 -3.03766432e+00 -2.87215152e+00 -1.87018573e+00\n",
      " -8.98087641e-01 -3.18825110e-01 -6.05973884e-01  1.99449001e+00\n",
      " -4.20279209e+00 -4.00806603e+00 -5.39521618e+00  3.90252532e+00\n",
      " -3.05000841e+00 -8.41928391e-02 -2.59559907e+00 -2.38643182e+00\n",
      " -4.29409949e+00 -7.02304829e-01 -1.70993483e+00  8.03132059e-02\n",
      " -2.55796079e+00 -2.49411376e+00 -3.55013680e+00 -5.19194056e+00\n",
      " -1.80566860e+00 -3.52303621e-01  2.41553848e-01  1.81939560e+00\n",
      " -3.74477761e+00 -4.15759395e+00 -6.62114995e+00  2.72609474e+00\n",
      " -1.02008792e+00 -2.91187016e+00 -3.31313683e+00 -2.88357602e+00\n",
      " -5.71762173e-01  1.85811995e+00 -2.57289241e+00 -3.62227140e+00\n",
      " -2.50300529e+00 -2.56440733e+00 -4.52701179e+00 -2.87136245e+00\n",
      " -3.38994336e+00 -5.94021829e-02 -1.46199663e+00 -3.29857378e+00\n",
      " -3.29138269e+00 -4.95170264e+00 -6.19223447e+00 -6.50750524e-01\n",
      " -2.09421281e+00  4.17569718e-01 -2.96906647e+00 -3.46193731e+00\n",
      "  1.74355486e+00 -8.45571935e-01 -3.23655880e+00  2.51027323e+00\n",
      " -1.95353630e-02 -2.08639066e+00 -2.79761096e+00  1.98739998e+00\n",
      " -2.27500839e+00 -6.05592972e-01 -2.92060975e+00 -2.52312407e+00\n",
      "  4.41625498e+00 -5.24031806e+00 -6.49790532e+00 -3.98764075e-01\n",
      " -3.10872236e+00 -6.01140012e-01 -7.63551575e-01 -3.03530846e+00\n",
      " -1.13528391e-01  1.74715604e+00  1.23936117e+00 -3.37135710e-01\n",
      " -1.21074822e+00  4.64614635e+00 -1.51032399e-02 -2.50129761e+00\n",
      " -2.12633131e+00 -2.57534764e+00 -3.68005480e+00 -4.67964872e+00\n",
      " -3.12065241e+00 -3.73727096e+00 -5.88821376e+00 -3.94860171e-01\n",
      " -3.07056243e+00  5.17597992e-01 -2.97931423e+00 -1.68286142e+00\n",
      " -2.14087984e+00 -1.85770344e+00 -2.80805687e+00 -2.59003241e+00]\n",
      "fitness score at this local optimum: -3.1473743125857023\n"
     ]
    }
   ],
   "source": [
    "# defines PEPG (NES) solver\n",
    "pepg = PEPG(NPARAMS,                         # number of model parameters\n",
    "            sigma_init=0.5,                  # initial standard deviation\n",
    "            learning_rate=0.1,               # learning rate for standard deviation\n",
    "            learning_rate_decay=1.0,       # don't anneal the learning rate\n",
    "            popsize=NPOPULATION,             # population size\n",
    "            average_baseline=False,          # set baseline to average of batch\n",
    "            weight_decay=0.00,            # weight decay coefficient\n",
    "            rank_fitness=False,           # use rank rather than fitness numbers\n",
    "            forget_best=False)   \n",
    "pepg_history = test_solver(pepg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = ga.ask()\n",
    "evluate_func(model, solutions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = model.forward(np.ones([1,12]))\n",
    "#model.forward(X[0])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([20, 12]), array([20, 20]), array([11, 20])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lyr_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ARC]",
   "language": "python",
   "name": "conda-env-ARC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
