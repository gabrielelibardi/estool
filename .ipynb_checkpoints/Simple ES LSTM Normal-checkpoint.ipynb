{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cma\n",
    "from es import SimpleGA, CMAES, PEPG, OpenES\n",
    "\n",
    "def sigmoid(x):\n",
    "    z = 1/(1 + np.exp(-x)) \n",
    "    return z\n",
    "\n",
    "def BCE_loss(y,p):\n",
    "    return np.sum(-y*np.log(p) - (1 - y)*np.log(1 - p))\n",
    "\n",
    "\n",
    "def binarize(x):\n",
    "    res = x > 0.5\n",
    "    return res.astype(int)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "  return np.maximum(x, 0)\n",
    "\n",
    "def passthru(x):\n",
    "  return x\n",
    "\n",
    "# useful for discrete actions\n",
    "def softmax(x):\n",
    "  e_x = np.exp(x - np.max(x))\n",
    "  return e_x / e_x.sum(axis=0)\n",
    "\n",
    "# useful for discrete actions\n",
    "def sample(p):\n",
    "  return np.argmax(np.random.multinomial(1, p))\n",
    "\n",
    "\n",
    "class RNNCell:\n",
    "  def __init__(self, input_size, weight, bias):\n",
    "    self.input_size=input_size\n",
    "    self.weight = weight\n",
    "    self.bias = bias\n",
    "  def __call__(self, x, h):\n",
    "    concat = np.concatenate((x, h), axis=1)\n",
    "    hidden = np.matmul(concat, self.weight)+self.bias\n",
    "    return np.tanh(hidden)\n",
    "\n",
    "class RNNModel:\n",
    "  def __init__(self):\n",
    "    \n",
    "\n",
    "    self.hidden_size = 10\n",
    "\n",
    "    self.layer_1 = 10\n",
    "    self.layer_2 = 10\n",
    "\n",
    "    self.rnn_mode = True\n",
    "\n",
    "    self.input_size = 1\n",
    "    self.output_size = 1\n",
    "\n",
    "\n",
    "    self.shapes = [ (self.input_size + self.hidden_size, 1*self.hidden_size), # RNN weights\n",
    "                    (self.input_size + self.hidden_size, self.layer_1),# predict actions output\n",
    "                    (self.layer_1, self.output_size)] # predict actions output\n",
    "\n",
    "    self.weight = []\n",
    "    self.bias = []\n",
    "    self.param_count = 0\n",
    "\n",
    "    idx = 0\n",
    "    for shape in self.shapes:\n",
    "      self.weight.append(np.zeros(shape=shape))\n",
    "      self.bias.append(np.zeros(shape=shape[1]))\n",
    "      self.param_count += (np.product(shape) + shape[1])\n",
    "      idx += 1\n",
    "    \n",
    "    self.init_h = np.zeros((1, self.hidden_size))\n",
    "    self.h = self.init_h\n",
    "    self.param_count += 1*self.hidden_size\n",
    "    \n",
    "    self.rnn = RNNCell(self.input_size, self.weight[0], self.bias[0])\n",
    "\n",
    "  def reset(self):\n",
    "    self.h = self.init_h\n",
    "\n",
    "\n",
    "  def get_action(self, x):\n",
    "    obs = x.reshape(1, self.input_size)\n",
    "\n",
    "    # update rnn:\n",
    "    #update_obs = np.concatenate([obs, action], axis=1)\n",
    "    self.h = self.rnn(x, binarize(sigmoid(self.h)))\n",
    "\n",
    "    # get action\n",
    "    x = np.concatenate([x, self.h], axis=1)\n",
    "\n",
    "    # calculate action using 2 layer network from output\n",
    "    hidden = np.tanh(np.matmul(x, self.weight[1]) + self.bias[1])\n",
    "    action = sigmoid(np.matmul(hidden, self.weight[2]) + self.bias[2])\n",
    "\n",
    "    return action[0]\n",
    "\n",
    "  def set_model_params(self, model_params):\n",
    "    pointer = 0\n",
    "    for i in range(len(self.shapes)):\n",
    "      w_shape = self.shapes[i]\n",
    "      b_shape = self.shapes[i][1]\n",
    "      s_w = np.product(w_shape)\n",
    "      s = s_w + b_shape\n",
    "      chunk = np.array(model_params[pointer:pointer+s])\n",
    "      self.weight[i] = chunk[:s_w].reshape(w_shape)\n",
    "      self.bias[i] = chunk[s_w:].reshape(b_shape)\n",
    "      pointer += s\n",
    "    # rnn states\n",
    "    s = self.hidden_size\n",
    "    self.init_h = model_params[pointer:pointer+s].reshape((1, self.hidden_size))\n",
    "    self.h = self.init_h\n",
    "    self.rnn = RNNCell(self.input_size, self.weight[0], self.bias[0])\n",
    "\n",
    "  def load_model(self, filename):\n",
    "    with open(filename) as f:    \n",
    "      data = json.load(f)\n",
    "    print('loading file %s' % (filename))\n",
    "    self.data = data\n",
    "    model_params = np.array(data[0]) # assuming other stuff is in data\n",
    "    self.set_model_params(model_params)\n",
    "\n",
    "  def get_random_model_params(self, stdev=0.1):\n",
    "    return np.random.randn(self.param_count)*stdev\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNNModel()\n",
    "model.get_action(np.array([[4]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel()\n",
    "NPARAMS = model.param_count    # make this a 100-dimensinal problem.\n",
    "NPOPULATION = 401    # use population size of 101.\n",
    "MAX_ITERATION = 4000 # run each solver for 5000 generations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurrency_label(seq_len):\n",
    "    \n",
    "    labels = []\n",
    "    X = []\n",
    "\n",
    "    X = np.zeros([seq_len,1])\n",
    "    #X[0,:] = 1.0\n",
    "    for ii in range(seq_len):\n",
    "        if ii % 30 == 0:\n",
    "            labels.append(np.ones([1,1]))\n",
    "\n",
    "        else:\n",
    "            labels.append(np.zeros([1,1]))\n",
    "\n",
    "    return X, np.concatenate(labels, axis=0)\n",
    "\n",
    "def evluate_func(model, params):\n",
    "    model.set_model_params(params)\n",
    "    model.reset()\n",
    "    loss_cum = 0\n",
    "    Xs, labels  = recurrency_label(32)\n",
    "\n",
    "    for x, label in zip(Xs,labels):\n",
    "        \n",
    "\n",
    "        x = np.array([x])\n",
    "        pred = model.get_action(x)\n",
    "        \n",
    "        #print(label, pred)\n",
    "        loss = BCE_loss(label, pred)\n",
    "        loss_cum += loss\n",
    "    #print(loss_cum)\n",
    "    return loss_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# defines genetic algorithm solver\n",
    "ga = SimpleGA(NPARAMS,                # number of model parameters\n",
    "               sigma_init=0.5,        # initial standard deviation\n",
    "               popsize=NPOPULATION,   # population size\n",
    "               elite_ratio=0.05,       # percentage of the elites\n",
    "               forget_best=False,     # forget the historical best elites\n",
    "               weight_decay=0.00,     # weight decay coefficient\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness at iteration 10 -3.44652492127586\n",
      "fitness at iteration 20 -3.242280012729875\n",
      "fitness at iteration 30 -2.9699428357942117\n",
      "fitness at iteration 40 -2.0972683433944046\n",
      "fitness at iteration 50 -2.0972683433944046\n",
      "fitness at iteration 60 -2.0972683433944046\n",
      "fitness at iteration 70 -2.0972683433944046\n",
      "fitness at iteration 80 -2.0972683433944046\n",
      "fitness at iteration 90 -2.0972683433944046\n",
      "fitness at iteration 100 -1.8481849637938492\n",
      "fitness at iteration 110 -1.8481849637938492\n",
      "fitness at iteration 120 -1.8481849637938492\n",
      "fitness at iteration 130 -1.8481849637938492\n",
      "fitness at iteration 140 -1.8481849637938492\n",
      "fitness at iteration 150 -1.6408074532148296\n",
      "fitness at iteration 160 -1.6408074532148296\n",
      "fitness at iteration 170 -1.6408074532148296\n",
      "fitness at iteration 180 -1.6408074532148296\n",
      "fitness at iteration 190 -1.6408074532148296\n",
      "fitness at iteration 200 -1.6408074532148296\n",
      "fitness at iteration 210 -1.6408074532148296\n",
      "fitness at iteration 220 -1.6408074532148296\n",
      "fitness at iteration 230 -1.6408074532148296\n",
      "fitness at iteration 240 -1.6408074532148296\n",
      "fitness at iteration 250 -1.6408074532148296\n",
      "fitness at iteration 260 -1.609501442436031\n",
      "fitness at iteration 270 -1.609501442436031\n",
      "fitness at iteration 280 -1.609501442436031\n",
      "fitness at iteration 290 -1.609501442436031\n",
      "fitness at iteration 300 -1.609501442436031\n",
      "fitness at iteration 310 -1.609501442436031\n",
      "fitness at iteration 320 -1.4661672903133232\n",
      "fitness at iteration 330 -1.4661672903133232\n",
      "fitness at iteration 340 -1.4661672903133232\n",
      "fitness at iteration 350 -1.4661672903133232\n",
      "fitness at iteration 360 -1.4661672903133232\n",
      "fitness at iteration 370 -1.4661672903133232\n",
      "fitness at iteration 380 -1.4661672903133232\n",
      "fitness at iteration 390 -1.4661672903133232\n",
      "fitness at iteration 400 -1.4661672903133232\n",
      "fitness at iteration 410 -1.4661672903133232\n"
     ]
    }
   ],
   "source": [
    "fit_func = evluate_func\n",
    "# defines a function to use solver to solve fit_func\n",
    "def test_solver(solver):\n",
    "    history = []\n",
    "    for j in range(MAX_ITERATION):\n",
    "        solutions = solver.ask()\n",
    "        fitness_list = np.zeros(solver.popsize)\n",
    "        #print(solutions)\n",
    "        for i in range(solver.popsize):\n",
    "            fitness_list[i] = -fit_func(model,solutions[i])\n",
    "            #print(fit_func(model,solutions[i]))\n",
    "            \n",
    "\n",
    "        solver.tell(fitness_list)\n",
    "        result = solver.result() # first element is the best solution, second element is the best fitness\n",
    "        history.append(result[1])\n",
    "        if (j+1) % 10 == 0:\n",
    "            print(\"fitness at iteration\", (j+1), result[1])\n",
    "    print(\"local optimum discovered by solver:\\n\", result[0])\n",
    "    print(\"fitness score at this local optimum:\", result[1])\n",
    "    return history\n",
    "\n",
    "ga_history = test_solver(ga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100_w,201)-aCMA-ES (mu_w=52.9,w_1=4%) in dimension 261 (seed=409367, Wed Nov 25 16:23:01 2020)\n",
      "fitness at iteration 10 -3.7509716944780345\n",
      "fitness at iteration 20 -3.3457004519871556\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-27254c7520c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0msigma_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcma_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmaes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-129-789ff9935242>\u001b[0m in \u001b[0;36mtest_solver\u001b[0;34m(solver)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#print(solutions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mfitness_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;31m#print(fit_func(model,solutions[i]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-1728cb09a965>\u001b[0m in \u001b[0;36mevluate_func\u001b[0;34m(model, params)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#print(label, pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-e3a3d9ad5556>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# calculate action using 2 layer network from output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cmaes = CMAES(NPARAMS,\n",
    "              popsize=NPOPULATION,\n",
    "              weight_decay=0.0,\n",
    "              sigma_init = 2.0\n",
    "          )\n",
    "cma_history = test_solver(cmaes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness at iteration 10 -15.596323380356534\n",
      "fitness at iteration 20 -14.355225727035895\n",
      "fitness at iteration 30 -13.215810099109849\n",
      "fitness at iteration 40 -13.215810099109849\n",
      "fitness at iteration 50 -13.215810099109849\n",
      "fitness at iteration 60 -13.215810099109849\n",
      "fitness at iteration 70 -13.215810099109849\n",
      "fitness at iteration 80 -13.215810099109849\n",
      "fitness at iteration 90 -13.215810099109849\n",
      "fitness at iteration 100 -13.215810099109849\n",
      "fitness at iteration 110 -13.215810099109849\n",
      "fitness at iteration 120 -13.215810099109849\n",
      "fitness at iteration 130 -13.215810099109849\n",
      "fitness at iteration 140 -13.215810099109849\n",
      "fitness at iteration 150 -13.215810099109849\n",
      "fitness at iteration 160 -13.215810099109849\n",
      "fitness at iteration 170 -13.215810099109849\n",
      "fitness at iteration 180 -13.215810099109849\n",
      "fitness at iteration 190 -13.215810099109849\n",
      "fitness at iteration 200 -12.606098756646514\n",
      "fitness at iteration 210 -12.606098756646514\n",
      "fitness at iteration 220 -12.606098756646514\n",
      "fitness at iteration 230 -12.606098756646514\n",
      "fitness at iteration 240 -12.606098756646514\n",
      "fitness at iteration 250 -12.606098756646514\n",
      "fitness at iteration 260 -12.606098756646514\n",
      "fitness at iteration 270 -12.606098756646514\n",
      "fitness at iteration 280 -12.606098756646514\n",
      "fitness at iteration 290 -12.606098756646514\n",
      "fitness at iteration 300 -12.606098756646514\n",
      "fitness at iteration 310 -12.606098756646514\n",
      "fitness at iteration 320 -12.606098756646514\n",
      "fitness at iteration 330 -12.606098756646514\n",
      "fitness at iteration 340 -12.606098756646514\n",
      "fitness at iteration 350 -12.606098756646514\n",
      "fitness at iteration 360 -12.606098756646514\n",
      "fitness at iteration 370 -12.606098756646514\n",
      "fitness at iteration 380 -12.606098756646514\n",
      "fitness at iteration 390 -12.606098756646514\n",
      "fitness at iteration 400 -12.606098756646514\n",
      "fitness at iteration 410 -12.606098756646514\n",
      "fitness at iteration 420 -12.606098756646514\n",
      "fitness at iteration 430 -12.606098756646514\n",
      "fitness at iteration 440 -12.606098756646514\n",
      "fitness at iteration 450 -12.606098756646514\n",
      "fitness at iteration 460 -12.606098756646514\n",
      "fitness at iteration 470 -12.606098756646514\n",
      "fitness at iteration 480 -12.606098756646514\n",
      "fitness at iteration 490 -12.606098756646514\n",
      "fitness at iteration 500 -12.606098756646514\n",
      "fitness at iteration 510 -12.606098756646514\n",
      "fitness at iteration 520 -12.606098756646514\n",
      "fitness at iteration 530 -12.606098756646514\n",
      "fitness at iteration 540 -12.606098756646514\n",
      "fitness at iteration 550 -12.606098756646514\n",
      "fitness at iteration 560 -12.606098756646514\n",
      "fitness at iteration 570 -12.606098756646514\n",
      "fitness at iteration 580 -12.606098756646514\n",
      "fitness at iteration 590 -12.606098756646514\n",
      "fitness at iteration 600 -12.606098756646514\n",
      "fitness at iteration 610 -12.606098756646514\n",
      "fitness at iteration 620 -12.606098756646514\n",
      "fitness at iteration 630 -12.606098756646514\n",
      "fitness at iteration 640 -12.606098756646514\n",
      "fitness at iteration 650 -12.606098756646514\n",
      "fitness at iteration 660 -12.606098756646514\n",
      "fitness at iteration 670 -12.606098756646514\n",
      "fitness at iteration 680 -12.606098756646514\n",
      "fitness at iteration 690 -12.606098756646514\n",
      "fitness at iteration 700 -12.606098756646514\n",
      "fitness at iteration 710 -12.606098756646514\n",
      "fitness at iteration 720 -12.606098756646514\n",
      "fitness at iteration 730 -12.606098756646514\n",
      "fitness at iteration 740 -12.606098756646514\n",
      "fitness at iteration 750 -12.606098756646514\n",
      "fitness at iteration 760 -12.606098756646514\n",
      "fitness at iteration 770 -12.606098756646514\n",
      "fitness at iteration 780 -12.606098756646514\n",
      "fitness at iteration 790 -12.606098756646514\n",
      "fitness at iteration 800 -12.606098756646514\n",
      "fitness at iteration 810 -12.606098756646514\n",
      "fitness at iteration 820 -12.606098756646514\n",
      "fitness at iteration 830 -12.606098756646514\n",
      "fitness at iteration 840 -12.606098756646514\n",
      "fitness at iteration 850 -12.606098756646514\n",
      "fitness at iteration 860 -12.606098756646514\n",
      "fitness at iteration 870 -12.606098756646514\n",
      "fitness at iteration 880 -12.606098756646514\n",
      "fitness at iteration 890 -12.606098756646514\n",
      "fitness at iteration 900 -12.606098756646514\n",
      "fitness at iteration 910 -12.606098756646514\n",
      "fitness at iteration 920 -12.606098756646514\n",
      "fitness at iteration 930 -12.606098756646514\n",
      "fitness at iteration 940 -12.606098756646514\n",
      "fitness at iteration 950 -12.606098756646514\n",
      "fitness at iteration 960 -12.606098756646514\n",
      "fitness at iteration 970 -12.606098756646514\n",
      "fitness at iteration 980 -12.606098756646514\n",
      "fitness at iteration 990 -12.606098756646514\n",
      "fitness at iteration 1000 -12.606098756646514\n",
      "fitness at iteration 1010 -12.606098756646514\n",
      "fitness at iteration 1020 -12.606098756646514\n",
      "fitness at iteration 1030 -12.606098756646514\n",
      "fitness at iteration 1040 -12.606098756646514\n",
      "fitness at iteration 1050 -12.606098756646514\n",
      "fitness at iteration 1060 -12.606098756646514\n",
      "fitness at iteration 1070 -12.606098756646514\n",
      "fitness at iteration 1080 -12.606098756646514\n",
      "fitness at iteration 1090 -12.606098756646514\n",
      "fitness at iteration 1100 -12.606098756646514\n",
      "fitness at iteration 1110 -12.606098756646514\n",
      "fitness at iteration 1120 -12.606098756646514\n",
      "fitness at iteration 1130 -12.606098756646514\n",
      "fitness at iteration 1140 -12.606098756646514\n",
      "fitness at iteration 1150 -12.606098756646514\n",
      "fitness at iteration 1160 -12.606098756646514\n",
      "fitness at iteration 1170 -12.606098756646514\n",
      "fitness at iteration 1180 -12.606098756646514\n",
      "fitness at iteration 1190 -12.606098756646514\n",
      "fitness at iteration 1200 -12.606098756646514\n",
      "fitness at iteration 1210 -12.606098756646514\n",
      "fitness at iteration 1220 -12.606098756646514\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-395983c9a5dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mrank_fitness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;31m# use rank rather than fitness numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             forget_best=False)   \n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpepg_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpepg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-789ff9935242>\u001b[0m in \u001b[0;36mtest_solver\u001b[0;34m(solver)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#print(solutions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mfitness_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;31m#print(fit_func(model,solutions[i]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-184b4fb8185f>\u001b[0m in \u001b[0;36mevluate_func\u001b[0;34m(model, params)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#print(label, pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCE_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mloss_cum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#print(loss_cum)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# defines PEPG (NES) solver\n",
    "pepg = PEPG(NPARAMS,                         # number of model parameters\n",
    "            sigma_init=0.5,                  # initial standard deviation\n",
    "            learning_rate=0.01,               # learning rate for standard deviation\n",
    "            learning_rate_decay=1.0,       # don't anneal the learning rate\n",
    "            popsize=NPOPULATION,             # population size\n",
    "            average_baseline=False,          # set baseline to average of batch\n",
    "            weight_decay=0.00,            # weight decay coefficient\n",
    "            rank_fitness=False,           # use rank rather than fitness numbers\n",
    "            forget_best=False)   \n",
    "pepg_history = test_solver(pepg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = ga.ask()\n",
    "evluate_func(model, solutions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = model.forward(np.ones([1,12]))\n",
    "#model.forward(X[0])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([20, 12]), array([20, 20]), array([11, 20])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lyr_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAP: 81\n",
      "[93, 27, 71, 94, 68, 12, 35, 22, 25, 43]\n",
      "GAP: 64\n",
      "[93, 27, 71, 94, 68, 12, 35, 22, 25, 43]\n",
      "GAP: 49\n",
      "[93, 27, 71, 94, 68, 12, 35, 22, 25, 43]\n",
      "GAP: 36\n",
      "[93, 27, 71, 94, 68, 12, 35, 22, 25, 43]\n",
      "GAP: 25\n",
      "[93, 27, 71, 94, 68, 12, 35, 22, 25, 43]\n",
      "GAP: 16\n",
      "[93, 27, 71, 94, 68, 12, 35, 22, 25, 43]\n",
      "GAP: 9\n",
      "[43, 27, 71, 94, 68, 12, 35, 22, 25, 93]\n",
      "GAP: 4\n",
      "[25, 12, 35, 22, 43, 27, 71, 94, 68, 93]\n",
      "GAP: 1\n",
      "[12, 22, 25, 27, 35, 43, 68, 71, 93, 94]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def shellSort(arr, k): \n",
    "  \n",
    "    # Start with a big gap, then reduce the gap \n",
    "    n = len(arr) \n",
    "\n",
    "    \n",
    "    gap = (k -1)*(k-1)\n",
    "  \n",
    "    # Do a gapped insertion sort for this gap size. \n",
    "    # The first gap elements a[0..gap-1] are already in gapped  \n",
    "    # order keep adding one more element until the entire array \n",
    "    # is gap sorted \n",
    "    while gap > 0:\n",
    "        print('GAP:', gap)\n",
    "        for i in range(gap,n): \n",
    "  \n",
    "            # add a[i] to the elements that have been gap sorted \n",
    "            # save a[i] in temp and make a hole at position i \n",
    "            temp = arr[i] \n",
    "  \n",
    "            # shift earlier gap-sorted elements up until the correct \n",
    "            # location for a[i] is found \n",
    "            j = i \n",
    "            while  j >= gap and arr[j-gap] >temp: \n",
    "                arr[j] = arr[j-gap] \n",
    "                j -= gap \n",
    "  \n",
    "            # put temp (the original a[i]) in its correct location \n",
    "            arr[j] = temp\n",
    "        print(arr)\n",
    "        k = k - 1\n",
    "        gap = (k -1)*(k-1)\n",
    "\n",
    "  \n",
    "  \n",
    "# Driver code to test above \n",
    "arr = [93, 27, 71, 94, 68, 12, 35, 22, 25, 43]\n",
    "  \n",
    "n = len(arr) \n",
    "  \n",
    "shellSort(arr, len(arr)) \n",
    "  \n",
    "\n",
    "# This code is contributed by Mohit Kumra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ARC]",
   "language": "python",
   "name": "conda-env-ARC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
