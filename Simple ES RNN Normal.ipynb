{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import cma\n",
    "from es import SimpleGA, CMAES, PEPG, OpenES\n",
    "\n",
    "def sigmoid(x):\n",
    "    z = 1/(1 + np.exp(-x)) \n",
    "    return z\n",
    "\n",
    "def BCE_loss(y,p):\n",
    "    return np.mean(-y*np.log(p) - (1 - y)*np.log(1 - p))\n",
    "\n",
    "\n",
    "def binarize(x):\n",
    "    res = x > 0.5\n",
    "    return res.astype(int)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "  return np.maximum(x, 0)\n",
    "\n",
    "def passthru(x):\n",
    "  return x\n",
    "\n",
    "# useful for discrete actions\n",
    "def softmax(x):\n",
    "  e_x = np.exp(x - np.max(x))\n",
    "  return e_x / e_x.sum(axis=0)\n",
    "\n",
    "# useful for discrete actions\n",
    "def sample(p):\n",
    "  return np.argmax(np.random.multinomial(1, p))\n",
    "\n",
    "\n",
    "class RNNCell:\n",
    "  def __init__(self, input_size, weight, bias):\n",
    "    self.input_size=input_size\n",
    "    self.weight = weight\n",
    "    self.bias = bias\n",
    "  def __call__(self, x, h):\n",
    "    concat = np.concatenate((x, h), axis=1)\n",
    "    hidden = np.matmul(concat, self.weight)+self.bias\n",
    "    return np.tanh(hidden)\n",
    "\n",
    "class RNNModel:\n",
    "    def __init__(self):\n",
    "    \n",
    "\n",
    "        self.hidden_size = 10\n",
    "\n",
    "        self.layer_1 = 10\n",
    "        self.layer_2 = 10\n",
    "\n",
    "        self.rnn_mode = True\n",
    "\n",
    "        self.input_size = 1\n",
    "        self.output_size = 1\n",
    "        self.alpha = 0.0\n",
    "\n",
    "\n",
    "        self.shapes = [ (self.input_size + self.hidden_size, 1*self.hidden_size), # RNN weights\n",
    "                        (self.input_size + self.hidden_size, self.layer_1),# predict actions output\n",
    "                        (self.layer_1, self.output_size)] # predict actions output\n",
    "\n",
    "        self.weight = []\n",
    "        self.bias = []\n",
    "        self.param_count = 0\n",
    "\n",
    "        idx = 0\n",
    "        for shape in self.shapes:\n",
    "          self.weight.append(np.zeros(shape=shape))\n",
    "          self.bias.append(np.zeros(shape=shape[1]))\n",
    "          self.param_count += (np.product(shape) + shape[1])\n",
    "          idx += 1\n",
    "\n",
    "        self.init_h = np.zeros((1, self.hidden_size))\n",
    "        self.h = self.init_h\n",
    "        self.param_count += 1*self.hidden_size\n",
    "\n",
    "        self.rnn = RNNCell(self.input_size, self.weight[0], self.bias[0])\n",
    "\n",
    "    def reset(self):\n",
    "        self.h = sigmoid(self.init_h)\n",
    "\n",
    "\n",
    "    def get_action(self, x):\n",
    "        obs = x.reshape(1, self.input_size)\n",
    "\n",
    "        # update rnn:\n",
    "        #update_obs = np.concatenate([obs, action], axis=1)\n",
    "       \n",
    "        self.h = sigmoid(self.rnn(x, self.h))\n",
    "\n",
    "        \n",
    "        # get action\n",
    "        x = np.concatenate([x, self.h], axis=1)\n",
    "\n",
    "        # calculate action using 2 layer network from output\n",
    "        hidden = np.tanh(np.matmul(x, self.weight[1]) + self.bias[1])\n",
    "        action = sigmoid(np.matmul(hidden, self.weight[2]) + self.bias[2])\n",
    "\n",
    "        return action[0]\n",
    "\n",
    "    def set_model_params(self, model_params):\n",
    "        pointer = 0\n",
    "        for i in range(len(self.shapes)):\n",
    "          w_shape = self.shapes[i]\n",
    "          b_shape = self.shapes[i][1]\n",
    "          s_w = np.product(w_shape)\n",
    "          s = s_w + b_shape\n",
    "          chunk = np.array(model_params[pointer:pointer+s])\n",
    "          self.weight[i] = chunk[:s_w].reshape(w_shape)\n",
    "          self.bias[i] = chunk[s_w:].reshape(b_shape)\n",
    "          pointer += s\n",
    "        # rnn states\n",
    "        s = self.hidden_size\n",
    "        self.init_h = model_params[pointer:pointer+s].reshape((1, self.hidden_size))\n",
    "        self.h = self.init_h\n",
    "        self.rnn = RNNCell(self.input_size, self.weight[0], self.bias[0])\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        with open(filename) as f:    \n",
    "          data = json.load(f)\n",
    "        print('loading file %s' % (filename))\n",
    "        self.data = data\n",
    "        model_params = np.array(data[0]) # assuming other stuff is in data\n",
    "        self.set_model_params(model_params)\n",
    "\n",
    "    def get_random_model_params(self, stdev=0.1):\n",
    "        return np.random.randn(self.param_count)*stdev\n",
    "\n",
    "    def update_alpha(self):\n",
    "        self.alpha += 0.001\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RNNModel2:\n",
    "    def __init__(self):\n",
    "    \n",
    "\n",
    "        self.hidden_size = 10\n",
    "\n",
    "        self.layer_1 = 10\n",
    "        self.layer_2 = 10\n",
    "\n",
    "        self.rnn_mode = True\n",
    "\n",
    "        self.input_size = 1\n",
    "        self.output_size = 10\n",
    "        self.alpha = 1.0\n",
    "\n",
    "\n",
    "        self.shapes = [ (self.input_size + self.hidden_size, 1*self.hidden_size), # RNN weights\n",
    "                        (self.input_size + self.hidden_size, self.layer_1),# predict actions output\n",
    "                        (self.layer_1, self.output_size)] # predict actions output\n",
    "\n",
    "        self.weight = []\n",
    "        self.bias = []\n",
    "        self.param_count = 0\n",
    "\n",
    "        idx = 0\n",
    "        for shape in self.shapes:\n",
    "          self.weight.append(np.zeros(shape=shape))\n",
    "          self.bias.append(np.zeros(shape=shape[1]))\n",
    "          self.param_count += (np.product(shape) + shape[1])\n",
    "          idx += 1\n",
    "\n",
    "        self.init_h = np.zeros((1, self.hidden_size))\n",
    "        self.h = self.init_h\n",
    "        self.param_count += 1*self.hidden_size\n",
    "\n",
    "        self.rnn = RNNCell(self.input_size, self.weight[0], self.bias[0])\n",
    "\n",
    "    def reset(self):\n",
    "        self.h = self.init_h\n",
    "        self.h =  (1 - self.alpha)*sigmoid(self.h)+ self.alpha*binarize(sigmoid(self.h))\n",
    "\n",
    "\n",
    "    def get_action(self, x):\n",
    "        obs = x.reshape(1, self.input_size)\n",
    "\n",
    "        # update rnn:\n",
    "        #update_obs = np.concatenate([obs, action], axis=1)\n",
    "        h =  (1 - self.alpha)*sigmoid(self.h)+ self.alpha*binarize(sigmoid(self.h))\n",
    "        self.h = self.rnn(x, h)\n",
    "\n",
    "        h =  (1 - self.alpha)*sigmoid(self.h)+ self.alpha*binarize(sigmoid(self.h))\n",
    "        # get action\n",
    "        x = np.concatenate([x, h], axis=1)\n",
    "\n",
    "        # calculate action using 2 layer network from output\n",
    "        hidden = np.tanh(np.matmul(x, self.weight[1]) + self.bias[1])\n",
    "        action = sigmoid(np.matmul(hidden, self.weight[2]) + self.bias[2])\n",
    "\n",
    "        return action[0]\n",
    "\n",
    "    def set_model_params(self, model_params):\n",
    "        pointer = 0\n",
    "        for i in range(len(self.shapes)):\n",
    "          w_shape = self.shapes[i]\n",
    "          b_shape = self.shapes[i][1]\n",
    "          s_w = np.product(w_shape)\n",
    "          s = s_w + b_shape\n",
    "          chunk = np.array(model_params[pointer:pointer+s])\n",
    "          self.weight[i] = chunk[:s_w].reshape(w_shape)\n",
    "          self.bias[i] = chunk[s_w:].reshape(b_shape)\n",
    "          pointer += s\n",
    "        # rnn states\n",
    "        s = self.hidden_size\n",
    "        self.init_h = model_params[pointer:pointer+s].reshape((1, self.hidden_size))\n",
    "        self.h = self.init_h\n",
    "        self.rnn = RNNCell(self.input_size, self.weight[0], self.bias[0])\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        with open(filename) as f:    \n",
    "          data = json.load(f)\n",
    "        print('loading file %s' % (filename))\n",
    "        self.data = data\n",
    "        model_params = np.array(data[0]) # assuming other stuff is in data\n",
    "        self.set_model_params(model_params)\n",
    "\n",
    "    def get_random_model_params(self, stdev=0.1):\n",
    "        return np.random.randn(self.param_count)*stdev\n",
    "\n",
    "    def update_alpha(self):\n",
    "        self.alpha += 0.001\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel()\n",
    "model2 = RNNModel2()\n",
    "#model.get_action(np.array([[4]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NPARAMS = model.param_count   # make this a 100-dimensinal problem.\n",
    "NPOPULATION = 410    # use population size of 101.\n",
    "MAX_ITERATION = 4010 # run each solver for 5000 generations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recurrency_label(seq_len):\n",
    "    \n",
    "    labels = []\n",
    "    X = []\n",
    "\n",
    "    X = np.zeros([seq_len,1])\n",
    "    #X[0,:] = 1.0\n",
    "    for ii in range(seq_len):\n",
    "        if ii % 40 == 0:\n",
    "            labels.append(np.ones([1,1]))\n",
    "\n",
    "        else:\n",
    "            labels.append(np.zeros([1,1]))\n",
    "\n",
    "    return X, np.concatenate(labels, axis=0)\n",
    "\n",
    "def evluate_func(data):\n",
    "    model, params =  data\n",
    "    model.set_model_params(params)\n",
    "    model.reset()\n",
    "    loss_cum = 0\n",
    "    Xs, labels  = recurrency_label(42)\n",
    "\n",
    "    for x, label in zip(Xs,labels):\n",
    "        \n",
    "\n",
    "        x = np.array([x])\n",
    "        pred = model.get_action(x)\n",
    "        \n",
    "        #print(label, pred)\n",
    "        loss = BCE_loss(label, pred)\n",
    "        loss_cum += loss\n",
    "    #print(loss_cum)\n",
    "    return -loss_cum\n",
    "\n",
    "def evluate_func(data):\n",
    "    model, params =  data\n",
    "    model.set_model_params(params)\n",
    "    model.reset()\n",
    "    loss_cum = 0\n",
    "    Xs, labels  = recurrency_label(42)\n",
    "\n",
    "    for x, label in zip(Xs,labels):\n",
    "        \n",
    "\n",
    "        x = np.array([x])\n",
    "        pred = model.get_action(x)\n",
    "        \n",
    "        #print(label, pred)\n",
    "        loss = BCE_loss(label, pred)\n",
    "        loss_cum += loss\n",
    "    #print(loss_cum)\n",
    "    return -loss_cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# defines genetic algorithm solver\n",
    "ga = SimpleGA(NPARAMS,                # number of model parameters\n",
    "               sigma_init=0.5,        # initial standard deviation\n",
    "               popsize=NPOPULATION,   # population size\n",
    "               elite_ratio=0.1,       # percentage of the elites\n",
    "               forget_best=False,     # forget the historical best elites\n",
    "               weight_decay=0.00,     # weight decay coefficient\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "fitness at iteration 10 -4.938518463346954\n",
      "fitness at iteration 20 -4.531225489333141\n",
      "fitness at iteration 30 -4.144667134398752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-26:\n",
      "Process ForkPoolWorker-30:\n",
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-28:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-19:\n",
      "Process ForkPoolWorker-24:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-29:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-18:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-17:\n",
      "Process ForkPoolWorker-27:\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-8:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Process ForkPoolWorker-16:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-12:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-10:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/shared/gabriele/miniconda/envs/ARC/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(mp.cpu_count())\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "fit_func = evluate_func\n",
    "# defines a function to use solver to solve fit_func\n",
    "def test_solver(solver):\n",
    "    history = []\n",
    "    j = 0\n",
    "    while True:\n",
    "        solutions = solver.ask()\n",
    "        fitness_list = np.zeros(solver.popsize)\n",
    "        #print(solutions)\n",
    "        fitness_list = pool.map(fit_func, [(model,solutions[i]) for i in range(solver.popsize)])\n",
    "            \n",
    "\n",
    "        solver.tell(fitness_list)\n",
    "        result = solver.result() # first element is the best solution, second element is the best fitness\n",
    "        history.append(result[1])\n",
    "        if (j+1) % 10 == 0:\n",
    "            print(\"fitness at iteration\", (j+1), result[1])\n",
    "#             print(\"Best:\",solver.elite_rewards[0])   \n",
    "            \n",
    "#         if -solver.elite_rewards[0] < 1:\n",
    "#             model.update_alpha()\n",
    "#             print('Alpha changed to', model.alpha)\n",
    "#             for kk in range(len(solver.elite_rewards)):\n",
    "#                 solver.elite_rewards[kk] = fit_func((model,solver.elite_params[kk]))\n",
    "#                 solver.forget_best = True\n",
    "#             else:\n",
    "#                 solver.forget_best = False\n",
    "        if -result[1] <= 0.0001:\n",
    "            print(\"local optimum discovered by solver:\\n\", result[0])\n",
    "            print(\"fitness score at this local optimum:\", result[1])\n",
    "            return history, result\n",
    "        j += 1\n",
    "        \n",
    "             \n",
    "    \n",
    "\n",
    "ga_history, result = test_solver(ga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "def MSE_loss(y,p):\n",
    "    \n",
    "    return np.mean(np.abs(y - p))\n",
    "\n",
    "\n",
    "def evluate_func2(data):\n",
    "    model, target_model, params =  data\n",
    "    model.set_model_params(params)\n",
    "    model.reset()\n",
    "    target_model.reset()\n",
    "    loss_cum = 0\n",
    "    Xs, labels  = recurrency_label(42)\n",
    "\n",
    "    for x, label in zip(Xs,labels):\n",
    "        \n",
    "\n",
    "        x = np.array([x])\n",
    "        ac = target_model.get_action(x)\n",
    "        pred = model.get_action(x)\n",
    "        \n",
    "        \n",
    "        #print(label, pred)\n",
    "        loss = MSE_loss(target_model.h, pred)\n",
    "#         print(target_model.h, pred)\n",
    "        loss_cum += loss\n",
    "    #print(loss_cum)\n",
    "    return -loss_cum\n",
    "\n",
    "ga = SimpleGA(model2.param_count,                # number of model parameters\n",
    "               sigma_init=0.5,        # initial standard deviation\n",
    "               popsize=NPOPULATION,   # population size\n",
    "               elite_ratio=0.1,       # percentage of the elites\n",
    "               forget_best=False,     # forget the historical best elites\n",
    "               weight_decay=0.00,     # weight decay coefficient\n",
    "              )\n",
    "\n",
    "\n",
    "print(mp.cpu_count())\n",
    "\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "fit_func = evluate_func2\n",
    "# defines a function to use solver to solve fit_func\n",
    "def test_solver(solver, target_model):\n",
    "    history = []\n",
    "    j = 0\n",
    "    while True:\n",
    "        solutions = solver.ask()\n",
    "        fitness_list = np.zeros(solver.popsize)\n",
    "\n",
    "        fitness_list = pool.map(fit_func, [(model2, target_model, solutions[i]) for i in range(solver.popsize)])\n",
    "            \n",
    "\n",
    "        solver.tell(fitness_list)\n",
    "        result = solver.result() # first element is the best solution, second element is the best fitness\n",
    "        history.append(result[1])\n",
    "        if (j+1) % 10 == 0:\n",
    "            print(\"fitness at iteration\", (j+1), result[1])\n",
    "        \n",
    "\n",
    "        if result[1] >= 0.0001:\n",
    "            break\n",
    "        #j += 1\n",
    "        \n",
    "             \n",
    "    print(\"local optimum discovered by solver:\\n\", result[0])\n",
    "    print(\"fitness score at this local optimum:\", result[1])\n",
    "    return history, result\n",
    "\n",
    "model.set_model_params(result[0])\n",
    "target_model = model\n",
    "#print(target_model)\n",
    "ga_history, result = test_solver(ga, target_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ga.elite_params)\n",
    "ga.elite_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6042791e59ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#print(loss_cum)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mloss_cum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mevluate_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "def evluate_func(model, target_model, params):\n",
    "#     model, target_model, params =  data\n",
    "    model.set_model_params(params)\n",
    "    model.reset()\n",
    "    target_model.reset()\n",
    "    loss_cum = 0\n",
    "    Xs, labels  = recurrency_label(42)\n",
    "\n",
    "    for x, label in zip(Xs,labels):\n",
    "        \n",
    "\n",
    "        x = np.array([x])\n",
    "        ac = target_model.get_action(x)\n",
    "        pred = model.get_action(x)\n",
    "        \n",
    "        #print(binarize(model.h))\n",
    "        \n",
    "        #print(label, pred)\n",
    "        loss = BCE_loss(target_model.h, pred)\n",
    "        print(target_model.h[0,3],pred[6])\n",
    "        loss_cum += loss\n",
    "    #print(loss_cum)\n",
    "    return -loss_cum\n",
    "evluate_func(model2,target_model, result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaes = CMAES(NPARAMS,\n",
    "              popsize=NPOPULATION,\n",
    "              weight_decay=0.0,\n",
    "              sigma_init = 2.0\n",
    "          )\n",
    "cma_history = test_solver(cmaes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines PEPG (NES) solver\n",
    "pepg = PEPG(NPARAMS,                         # number of model parameters\n",
    "            sigma_init=0.5,                  # initial standard deviation\n",
    "            learning_rate=0.01,               # learning rate for standard deviation\n",
    "            learning_rate_decay=1.0,       # don't anneal the learning rate\n",
    "            popsize=NPOPULATION,             # population size\n",
    "            average_baseline=False,          # set baseline to average of batch\n",
    "            weight_decay=0.00,            # weight decay coefficient\n",
    "            rank_fitness=False,           # use rank rather than fitness numbers\n",
    "            forget_best=False)   \n",
    "pepg_history = test_solver(pepg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = ga.ask()\n",
    "evluate_func(model, solutions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = model.forward(np.ones([1,12]))\n",
    "#model.forward(X[0])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([20, 12]), array([20, 20]), array([11, 20])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lyr_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ARC]",
   "language": "python",
   "name": "conda-env-ARC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
