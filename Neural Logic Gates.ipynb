{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cma\n",
    "from es import SimpleGA, CMAES, PEPG, OpenES\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    z = 1/(1 + np.exp(-x)) \n",
    "    return z\n",
    "\n",
    "def BCE_loss(y,p):\n",
    "    return np.sum(-y*np.log(p) - (1 - y)*np.log(1 - p))\n",
    "\n",
    "\n",
    "class gate_layer():\n",
    "    def __init__(self,dims, n_channels= 1, AND_OR = 1):\n",
    "        \n",
    "        # AND_OR = TRUE  : it is an AND gate\n",
    "        # AND_OR = FALSE : it is an OR gate\n",
    "        \n",
    "        self.AND_OR = AND_OR\n",
    "        self.n_channels = n_channels\n",
    "        dims[0] = n_channels\n",
    "        self.w =  np.random.normal(-3, 1, dims)\n",
    "  \n",
    "    def forward(self, X):\n",
    "       \n",
    "        X = np.repeat(X, self.n_channels, axis=0)\n",
    "\n",
    "        m = sigmoid(self.w)\n",
    "\n",
    "        if self.AND_OR == 1:\n",
    "            filtered_X = 1 - m *(1 - X) \n",
    "            \n",
    "            return np.prod(filtered_X,1)[np.newaxis,...]\n",
    "        \n",
    "        if self.AND_OR == 2:\n",
    "\n",
    "            filtered_X = m*X\n",
    "           \n",
    "            return (1- np.prod(1 - filtered_X,1))[np.newaxis,...]\n",
    "        \n",
    "        if self.AND_OR == 3:\n",
    "            # inverter\n",
    "            filtered_X = m*X\n",
    "            res = ones - filtered_X\n",
    "\n",
    "            return res\n",
    "            \n",
    "    \n",
    "class Model():\n",
    "    \n",
    "    def __init__(self, n_pop= 5000, cutoff = 5000):\n",
    "        \n",
    "        self.layers = []\n",
    "        self.n_pop = n_pop\n",
    "        self.cutoff = cutoff\n",
    "        \n",
    "    def add_layer(self,dims, n_channels, AND_OR=True, head = False):\n",
    "        # add output size arg\n",
    "        \n",
    "        lyr = gate_layer(dims, n_channels=n_channels, AND_OR=AND_OR)\n",
    "        self.layers.append(lyr)\n",
    "\n",
    "        \n",
    "    def forward(self,x, h, c):\n",
    "        inv_x = np.ones(x.shape).to(device) - x\n",
    "        aug_x = np.concatenate([x, inv_x], axis=2)\n",
    "        \n",
    "        inv_h = np.ones(h.shape).to(device) - x\n",
    "        aug_h = np.concatenate([h, inv_h], axis=2)\n",
    "\n",
    "        \n",
    "        #print(h_[0,3,:])\n",
    "        \n",
    "        xh = np.concatenate([aug_x,aug_h], axis=2)\n",
    "\n",
    "        \n",
    "        xh = self.layers[0].forward(xh)\n",
    "        xh = self.layers[1].forward(xh)\n",
    "        \n",
    "        \n",
    "        i, g, f, o = torch.split(xh,4,axis=2)\n",
    "       \n",
    "        \n",
    "        # g is old c??\n",
    "        \n",
    "        #new_c = 1 - (1 - (c * f))*(1-(g* i))\n",
    "        new_c = c*f + (1 -f)*i \n",
    "        new_h = new_c*o\n",
    "        \n",
    "        # END LSTM\n",
    "        \n",
    "        out = self.layers[2].forward(new_h)\n",
    "        Y_ = self.layers[3].forward(out)\n",
    "        \n",
    "        return new_h, new_c, Y_\n",
    "    \n",
    "\n",
    "    \n",
    "    def params(self):\n",
    "        # returns a list of the parameters to give to the optimizer\n",
    "        self.para = []\n",
    "\n",
    "        for layer in self.layers:\n",
    "        \n",
    "            self.para.append(layer.w)\n",
    "            \n",
    "        return self.para\n",
    "    \n",
    "\n",
    "            \n",
    "        \n",
    "    \n",
    "def recurrency_label(seq_len):\n",
    "    \n",
    "    labels = []\n",
    "    X = []\n",
    "\n",
    "    X = np.zeros([seq_len,1])\n",
    "    #X[0,:] = 1.0\n",
    "    for ii in range(seq_len):\n",
    "        \n",
    "        if ii % 4 == 0:\n",
    "            labels.append(np.ones([1,1]))\n",
    "\n",
    "        else:\n",
    "            labels.append(np.zeros([1,1]))\n",
    "\n",
    "    \n",
    "    return X, np.concatenate(labels, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "def evluate_func(model, params):\n",
    "    model.set_model_params(params)\n",
    "    loss_cum = 0\n",
    "    Xs, labels  = recurrency_label(10)\n",
    "    \n",
    "#     X = np.ones([1,1])\n",
    "#     inv_X = 1 - X\n",
    "\n",
    "#     aug_X = np.concatenate([X, inv_X], axis=1)\n",
    "    h_ = np.zeros([1,15])\n",
    "    c_ = np.zeros([1,15])\n",
    "\n",
    "    h_[0,0] = 1.0\n",
    "#     xh = np.concatenate([aug_X,h_], axis=1)\n",
    "#     _, h_ = model.forward(xh)\n",
    "\n",
    "    for X, label in zip(Xs,labels):\n",
    "        \n",
    "        inv_X = 1- X\n",
    "        \n",
    "        aug_X = np.concatenate([X, inv_X], axis=0)\n",
    "        \n",
    "        xh = np.concatenate([aug_X[np.newaxis,...],h_], axis=1)\n",
    "\n",
    "        h, c_, Y_= LSTM.forward(x, h, c_)\n",
    "        \n",
    "        pred = out[:,0:1]\n",
    "        h_ = np.copy(out[:,1:])\n",
    "\n",
    "        #print(label, pred)\n",
    "        loss = BCE_loss(label, pred)\n",
    "        loss_cum += loss\n",
    "    \n",
    "    return loss_cum\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'num_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f77a4cb17f74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mNPARAMS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# make this a 100-dimensinal problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mNPOPULATION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4001\u001b[0m    \u001b[0;31m# use population size of 101.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mMAX_ITERATION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4000\u001b[0m \u001b[0;31m# run each solver for 5000 generations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'num_params'"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.add_layer([1,12], n_channels = 20, AND_OR=1)\n",
    "model.add_layer([1,20], n_channels = 11, AND_OR=2)\n",
    "\n",
    "\n",
    "\n",
    "NPARAMS = model.num_params()       # make this a 100-dimensinal problem.\n",
    "NPOPULATION = 4001    # use population size of 101.\n",
    "MAX_ITERATION = 4000 # run each solver for 5000 generations.\n",
    "\n",
    "\n",
    "# defines genetic algorithm solver\n",
    "ga = SimpleGA(NPARAMS,                # number of model parameters\n",
    "               sigma_init=0.5,        # initial standard deviation\n",
    "               popsize=NPOPULATION,   # population size\n",
    "               elite_ratio=0.1,       # percentage of the elites\n",
    "               forget_best=False,     # forget the historical best elites\n",
    "               weight_decay=0.00,     # weight decay coefficient\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_func = evluate_func\n",
    "# defines a function to use solver to solve fit_func\n",
    "def test_solver(solver):\n",
    "    history = []\n",
    "    for j in range(MAX_ITERATION):\n",
    "        solutions = solver.ask()\n",
    "        fitness_list = np.zeros(solver.popsize)\n",
    "        #print(solutions)\n",
    "        for i in range(solver.popsize):\n",
    "            fitness_list[i] = -fit_func(model,solutions[i])\n",
    "            #print(fit_func(model,solutions[i]))\n",
    "            \n",
    "\n",
    "        solver.tell(fitness_list)\n",
    "        result = solver.result() # first element is the best solution, second element is the best fitness\n",
    "        history.append(result[1])\n",
    "        if (j+1) % 10 == 0:\n",
    "            print(\"fitness at iteration\", (j+1), result[1])\n",
    "    print(\"local optimum discovered by solver:\\n\", result[0])\n",
    "    print(\"fitness score at this local optimum:\", result[1])\n",
    "    return history\n",
    "\n",
    "ga_history = test_solver(ga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000_w,4000)-aCMA-ES (mu_w=1006.8,w_1=0%) in dimension 460 (seed=103839, Wed Jul 29 20:56:18 2020)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8d9d72de69d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0msigma_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcma_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmaes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-789ff9935242>\u001b[0m in \u001b[0;36mtest_solver\u001b[0;34m(solver)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_ITERATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0msolutions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mfitness_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#print(solutions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace7/Unity3D/gabriele/Animal-AI/ARC/estool/es.py\u001b[0m in \u001b[0;36mask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m'''returns a list of parameters'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cmaes = CMAES(NPARAMS,\n",
    "              popsize=NPOPULATION,\n",
    "              weight_decay=0.0,\n",
    "              sigma_init = 0.5\n",
    "          )\n",
    "cma_history = test_solver(cmaes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness at iteration 10 -5.060351721810443\n",
      "fitness at iteration 20 -5.039915157148965\n",
      "fitness at iteration 30 -5.039915157148965\n",
      "fitness at iteration 40 -4.786325644061899\n",
      "fitness at iteration 50 -4.542477245908696\n",
      "fitness at iteration 60 -4.429039767539853\n",
      "fitness at iteration 70 -4.251950382815559\n",
      "fitness at iteration 80 -4.0853189386801185\n",
      "fitness at iteration 90 -3.9931903311926185\n",
      "fitness at iteration 100 -3.920931923563131\n",
      "fitness at iteration 110 -3.8404116734408658\n",
      "fitness at iteration 120 -3.7180221391675548\n",
      "fitness at iteration 130 -3.638605300471249\n",
      "fitness at iteration 140 -3.552462794918037\n",
      "fitness at iteration 150 -3.4683311834682544\n",
      "fitness at iteration 160 -3.4211360793875167\n",
      "fitness at iteration 170 -3.380197272642628\n",
      "fitness at iteration 180 -3.3586081468875624\n",
      "fitness at iteration 190 -3.3193830277422918\n",
      "fitness at iteration 200 -3.2854970680712694\n",
      "fitness at iteration 210 -3.2587221839715754\n",
      "fitness at iteration 220 -3.242087785954948\n",
      "fitness at iteration 230 -3.2322815547202497\n",
      "fitness at iteration 240 -3.223296964538718\n",
      "fitness at iteration 250 -3.216082771253576\n",
      "fitness at iteration 260 -3.205100297297819\n",
      "fitness at iteration 270 -3.1982464676443096\n",
      "fitness at iteration 280 -3.194766811874766\n",
      "fitness at iteration 290 -3.1868281730288577\n",
      "fitness at iteration 300 -3.180086406289786\n",
      "fitness at iteration 310 -3.177294883750995\n",
      "fitness at iteration 320 -3.1714597094651826\n",
      "fitness at iteration 330 -3.1689955794117846\n",
      "fitness at iteration 340 -3.168333999775288\n",
      "fitness at iteration 350 -3.1665410555109625\n",
      "fitness at iteration 360 -3.1638605235819575\n",
      "fitness at iteration 370 -3.1638605235819575\n",
      "fitness at iteration 380 -3.162694449486774\n",
      "fitness at iteration 390 -3.162694449486774\n",
      "fitness at iteration 400 -3.1625223952765693\n",
      "fitness at iteration 410 -3.1617881677244912\n",
      "fitness at iteration 420 -3.160398217823558\n",
      "fitness at iteration 430 -3.1585439635445254\n",
      "fitness at iteration 440 -3.156857494503659\n",
      "fitness at iteration 450 -3.1556290887628253\n",
      "fitness at iteration 460 -3.155038023857966\n",
      "fitness at iteration 470 -3.153561761712357\n",
      "fitness at iteration 480 -3.1526115554679417\n",
      "fitness at iteration 490 -3.152415331316435\n",
      "fitness at iteration 500 -3.151206501381537\n",
      "fitness at iteration 510 -3.1510687173699203\n",
      "fitness at iteration 520 -3.150806276477243\n",
      "fitness at iteration 530 -3.150437616206999\n",
      "fitness at iteration 540 -3.150142026461554\n",
      "fitness at iteration 550 -3.150030552120076\n",
      "fitness at iteration 560 -3.150030552120076\n",
      "fitness at iteration 570 -3.150030552120076\n",
      "fitness at iteration 580 -3.149912726573014\n",
      "fitness at iteration 590 -3.1498420446930138\n",
      "fitness at iteration 600 -3.1498420446930138\n",
      "fitness at iteration 610 -3.149698145553998\n",
      "fitness at iteration 620 -3.149698145553998\n",
      "fitness at iteration 630 -3.149698145553998\n",
      "fitness at iteration 640 -3.149698145553998\n",
      "fitness at iteration 650 -3.149698145553998\n",
      "fitness at iteration 660 -3.149698145553998\n",
      "fitness at iteration 670 -3.149698145553998\n",
      "fitness at iteration 680 -3.149569225257744\n",
      "fitness at iteration 690 -3.149569225257744\n",
      "fitness at iteration 700 -3.1495637704885033\n",
      "fitness at iteration 710 -3.149472546872231\n",
      "fitness at iteration 720 -3.149472546872231\n",
      "fitness at iteration 730 -3.149151482448712\n",
      "fitness at iteration 740 -3.1489782759750007\n",
      "fitness at iteration 750 -3.1489782759750007\n",
      "fitness at iteration 760 -3.1489782759750007\n",
      "fitness at iteration 770 -3.1489057041744157\n",
      "fitness at iteration 780 -3.1487553875120478\n",
      "fitness at iteration 790 -3.1486587978889484\n",
      "fitness at iteration 800 -3.1486147235177593\n",
      "fitness at iteration 810 -3.148295815298394\n",
      "fitness at iteration 820 -3.148295815298394\n",
      "fitness at iteration 830 -3.148295815298394\n",
      "fitness at iteration 840 -3.1482040938913713\n",
      "fitness at iteration 850 -3.1482040938913713\n",
      "fitness at iteration 860 -3.1481075321985674\n",
      "fitness at iteration 870 -3.14807774655413\n",
      "fitness at iteration 880 -3.1479399549831046\n",
      "fitness at iteration 890 -3.1479399549831046\n",
      "fitness at iteration 900 -3.1479399549831046\n",
      "fitness at iteration 910 -3.1478391186580286\n",
      "fitness at iteration 920 -3.1478391186580286\n",
      "fitness at iteration 930 -3.1477728761853543\n",
      "fitness at iteration 940 -3.1477728761853543\n",
      "fitness at iteration 950 -3.1477728761853543\n",
      "fitness at iteration 960 -3.1477728761853543\n",
      "fitness at iteration 970 -3.1477728761853543\n",
      "fitness at iteration 980 -3.1477362444176604\n",
      "fitness at iteration 990 -3.1477362444176604\n",
      "fitness at iteration 1000 -3.1477362444176604\n",
      "fitness at iteration 1010 -3.147682592801772\n",
      "fitness at iteration 1020 -3.1476163202076557\n",
      "fitness at iteration 1030 -3.1476163202076557\n",
      "fitness at iteration 1040 -3.1475915106870356\n",
      "fitness at iteration 1050 -3.1475915106870356\n",
      "fitness at iteration 1060 -3.1475915106870356\n",
      "fitness at iteration 1070 -3.1474677452000632\n",
      "fitness at iteration 1080 -3.1474677452000632\n",
      "fitness at iteration 1090 -3.1474677452000632\n",
      "fitness at iteration 1100 -3.1474677452000632\n",
      "fitness at iteration 1110 -3.1473743125857023\n",
      "fitness at iteration 1120 -3.1473743125857023\n",
      "fitness at iteration 1130 -3.1473743125857023\n",
      "fitness at iteration 1140 -3.1473743125857023\n",
      "fitness at iteration 1150 -3.1473743125857023\n",
      "fitness at iteration 1160 -3.1473743125857023\n",
      "fitness at iteration 1170 -3.1473743125857023\n",
      "fitness at iteration 1180 -3.1473743125857023\n",
      "fitness at iteration 1190 -3.1473743125857023\n",
      "fitness at iteration 1200 -3.1473743125857023\n",
      "fitness at iteration 1210 -3.1473743125857023\n",
      "fitness at iteration 1220 -3.1473743125857023\n",
      "fitness at iteration 1230 -3.1473743125857023\n",
      "fitness at iteration 1240 -3.1473743125857023\n",
      "fitness at iteration 1250 -3.1473743125857023\n",
      "fitness at iteration 1260 -3.1473743125857023\n",
      "fitness at iteration 1270 -3.1473743125857023\n",
      "fitness at iteration 1280 -3.1473743125857023\n",
      "fitness at iteration 1290 -3.1473743125857023\n",
      "fitness at iteration 1300 -3.1473743125857023\n",
      "fitness at iteration 1310 -3.1473743125857023\n",
      "fitness at iteration 1320 -3.1473743125857023\n",
      "fitness at iteration 1330 -3.1473743125857023\n",
      "fitness at iteration 1340 -3.1473743125857023\n",
      "fitness at iteration 1350 -3.1473743125857023\n",
      "fitness at iteration 1360 -3.1473743125857023\n",
      "fitness at iteration 1370 -3.1473743125857023\n",
      "fitness at iteration 1380 -3.1473743125857023\n",
      "fitness at iteration 1390 -3.1473743125857023\n",
      "fitness at iteration 1400 -3.1473743125857023\n",
      "fitness at iteration 1410 -3.1473743125857023\n",
      "fitness at iteration 1420 -3.1473743125857023\n",
      "fitness at iteration 1430 -3.1473743125857023\n",
      "fitness at iteration 1440 -3.1473743125857023\n",
      "fitness at iteration 1450 -3.1473743125857023\n",
      "fitness at iteration 1460 -3.1473743125857023\n",
      "fitness at iteration 1470 -3.1473743125857023\n",
      "fitness at iteration 1480 -3.1473743125857023\n",
      "fitness at iteration 1490 -3.1473743125857023\n",
      "fitness at iteration 1500 -3.1473743125857023\n",
      "fitness at iteration 1510 -3.1473743125857023\n",
      "fitness at iteration 1520 -3.1473743125857023\n",
      "fitness at iteration 1530 -3.1473743125857023\n",
      "fitness at iteration 1540 -3.1473743125857023\n",
      "fitness at iteration 1550 -3.1473743125857023\n",
      "fitness at iteration 1560 -3.1473743125857023\n",
      "fitness at iteration 1570 -3.1473743125857023\n",
      "fitness at iteration 1580 -3.1473743125857023\n",
      "fitness at iteration 1590 -3.1473743125857023\n",
      "fitness at iteration 1600 -3.1473743125857023\n",
      "fitness at iteration 1610 -3.1473743125857023\n",
      "fitness at iteration 1620 -3.1473743125857023\n",
      "fitness at iteration 1630 -3.1473743125857023\n",
      "fitness at iteration 1640 -3.1473743125857023\n",
      "fitness at iteration 1650 -3.1473743125857023\n",
      "fitness at iteration 1660 -3.1473743125857023\n",
      "fitness at iteration 1670 -3.1473743125857023\n",
      "fitness at iteration 1680 -3.1473743125857023\n",
      "fitness at iteration 1690 -3.1473743125857023\n",
      "fitness at iteration 1700 -3.1473743125857023\n",
      "fitness at iteration 1710 -3.1473743125857023\n",
      "fitness at iteration 1720 -3.1473743125857023\n",
      "fitness at iteration 1730 -3.1473743125857023\n",
      "fitness at iteration 1740 -3.1473743125857023\n",
      "fitness at iteration 1750 -3.1473743125857023\n",
      "fitness at iteration 1760 -3.1473743125857023\n",
      "fitness at iteration 1770 -3.1473743125857023\n",
      "fitness at iteration 1780 -3.1473743125857023\n",
      "fitness at iteration 1790 -3.1473743125857023\n",
      "fitness at iteration 1800 -3.1473743125857023\n",
      "fitness at iteration 1810 -3.1473743125857023\n",
      "fitness at iteration 1820 -3.1473743125857023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness at iteration 1830 -3.1473743125857023\n",
      "fitness at iteration 1840 -3.1473743125857023\n",
      "fitness at iteration 1850 -3.1473743125857023\n",
      "fitness at iteration 1860 -3.1473743125857023\n",
      "fitness at iteration 1870 -3.1473743125857023\n",
      "fitness at iteration 1880 -3.1473743125857023\n",
      "fitness at iteration 1890 -3.1473743125857023\n",
      "fitness at iteration 1900 -3.1473743125857023\n",
      "fitness at iteration 1910 -3.1473743125857023\n",
      "fitness at iteration 1920 -3.1473743125857023\n",
      "fitness at iteration 1930 -3.1473743125857023\n",
      "fitness at iteration 1940 -3.1473743125857023\n",
      "fitness at iteration 1950 -3.1473743125857023\n",
      "fitness at iteration 1960 -3.1473743125857023\n",
      "fitness at iteration 1970 -3.1473743125857023\n",
      "fitness at iteration 1980 -3.1473743125857023\n",
      "fitness at iteration 1990 -3.1473743125857023\n",
      "fitness at iteration 2000 -3.1473743125857023\n",
      "fitness at iteration 2010 -3.1473743125857023\n",
      "fitness at iteration 2020 -3.1473743125857023\n",
      "fitness at iteration 2030 -3.1473743125857023\n",
      "fitness at iteration 2040 -3.1473743125857023\n",
      "fitness at iteration 2050 -3.1473743125857023\n",
      "fitness at iteration 2060 -3.1473743125857023\n",
      "fitness at iteration 2070 -3.1473743125857023\n",
      "fitness at iteration 2080 -3.1473743125857023\n",
      "fitness at iteration 2090 -3.1473743125857023\n",
      "fitness at iteration 2100 -3.1473743125857023\n",
      "fitness at iteration 2110 -3.1473743125857023\n",
      "fitness at iteration 2120 -3.1473743125857023\n",
      "fitness at iteration 2130 -3.1473743125857023\n",
      "fitness at iteration 2140 -3.1473743125857023\n",
      "fitness at iteration 2150 -3.1473743125857023\n",
      "fitness at iteration 2160 -3.1473743125857023\n",
      "fitness at iteration 2170 -3.1473743125857023\n",
      "fitness at iteration 2180 -3.1473743125857023\n",
      "fitness at iteration 2190 -3.1473743125857023\n",
      "fitness at iteration 2200 -3.1473743125857023\n",
      "fitness at iteration 2210 -3.1473743125857023\n",
      "fitness at iteration 2220 -3.1473743125857023\n",
      "fitness at iteration 2230 -3.1473743125857023\n",
      "fitness at iteration 2240 -3.1473743125857023\n",
      "fitness at iteration 2250 -3.1473743125857023\n",
      "fitness at iteration 2260 -3.1473743125857023\n",
      "fitness at iteration 2270 -3.1473743125857023\n",
      "fitness at iteration 2280 -3.1473743125857023\n",
      "fitness at iteration 2290 -3.1473743125857023\n",
      "fitness at iteration 2300 -3.1473743125857023\n",
      "fitness at iteration 2310 -3.1473743125857023\n",
      "fitness at iteration 2320 -3.1473743125857023\n",
      "fitness at iteration 2330 -3.1473743125857023\n",
      "fitness at iteration 2340 -3.1473743125857023\n",
      "fitness at iteration 2350 -3.1473743125857023\n",
      "fitness at iteration 2360 -3.1473743125857023\n",
      "fitness at iteration 2370 -3.1473743125857023\n",
      "fitness at iteration 2380 -3.1473743125857023\n",
      "fitness at iteration 2390 -3.1473743125857023\n",
      "fitness at iteration 2400 -3.1473743125857023\n",
      "fitness at iteration 2410 -3.1473743125857023\n",
      "fitness at iteration 2420 -3.1473743125857023\n",
      "fitness at iteration 2430 -3.1473743125857023\n",
      "fitness at iteration 2440 -3.1473743125857023\n",
      "fitness at iteration 2450 -3.1473743125857023\n",
      "fitness at iteration 2460 -3.1473743125857023\n",
      "fitness at iteration 2470 -3.1473743125857023\n",
      "fitness at iteration 2480 -3.1473743125857023\n",
      "fitness at iteration 2490 -3.1473743125857023\n",
      "fitness at iteration 2500 -3.1473743125857023\n",
      "fitness at iteration 2510 -3.1473743125857023\n",
      "fitness at iteration 2520 -3.1473743125857023\n",
      "fitness at iteration 2530 -3.1473743125857023\n",
      "fitness at iteration 2540 -3.1473743125857023\n",
      "fitness at iteration 2550 -3.1473743125857023\n",
      "fitness at iteration 2560 -3.1473743125857023\n",
      "fitness at iteration 2570 -3.1473743125857023\n",
      "fitness at iteration 2580 -3.1473743125857023\n",
      "fitness at iteration 2590 -3.1473743125857023\n",
      "fitness at iteration 2600 -3.1473743125857023\n",
      "fitness at iteration 2610 -3.1473743125857023\n",
      "fitness at iteration 2620 -3.1473743125857023\n",
      "fitness at iteration 2630 -3.1473743125857023\n",
      "fitness at iteration 2640 -3.1473743125857023\n",
      "fitness at iteration 2650 -3.1473743125857023\n",
      "fitness at iteration 2660 -3.1473743125857023\n",
      "fitness at iteration 2670 -3.1473743125857023\n",
      "fitness at iteration 2680 -3.1473743125857023\n",
      "fitness at iteration 2690 -3.1473743125857023\n",
      "fitness at iteration 2700 -3.1473743125857023\n",
      "fitness at iteration 2710 -3.1473743125857023\n",
      "fitness at iteration 2720 -3.1473743125857023\n",
      "fitness at iteration 2730 -3.1473743125857023\n",
      "fitness at iteration 2740 -3.1473743125857023\n",
      "fitness at iteration 2750 -3.1473743125857023\n",
      "fitness at iteration 2760 -3.1473743125857023\n",
      "fitness at iteration 2770 -3.1473743125857023\n",
      "fitness at iteration 2780 -3.1473743125857023\n",
      "fitness at iteration 2790 -3.1473743125857023\n",
      "fitness at iteration 2800 -3.1473743125857023\n",
      "fitness at iteration 2810 -3.1473743125857023\n",
      "fitness at iteration 2820 -3.1473743125857023\n",
      "fitness at iteration 2830 -3.1473743125857023\n",
      "fitness at iteration 2840 -3.1473743125857023\n",
      "fitness at iteration 2850 -3.1473743125857023\n",
      "fitness at iteration 2860 -3.1473743125857023\n",
      "fitness at iteration 2870 -3.1473743125857023\n",
      "fitness at iteration 2880 -3.1473743125857023\n",
      "fitness at iteration 2890 -3.1473743125857023\n",
      "fitness at iteration 2900 -3.1473743125857023\n",
      "fitness at iteration 2910 -3.1473743125857023\n",
      "fitness at iteration 2920 -3.1473743125857023\n",
      "fitness at iteration 2930 -3.1473743125857023\n",
      "fitness at iteration 2940 -3.1473743125857023\n",
      "fitness at iteration 2950 -3.1473743125857023\n",
      "fitness at iteration 2960 -3.1473743125857023\n",
      "fitness at iteration 2970 -3.1473743125857023\n",
      "fitness at iteration 2980 -3.1473743125857023\n",
      "fitness at iteration 2990 -3.1473743125857023\n",
      "fitness at iteration 3000 -3.1473743125857023\n",
      "fitness at iteration 3010 -3.1473743125857023\n",
      "fitness at iteration 3020 -3.1473743125857023\n",
      "fitness at iteration 3030 -3.1473743125857023\n",
      "fitness at iteration 3040 -3.1473743125857023\n",
      "fitness at iteration 3050 -3.1473743125857023\n",
      "fitness at iteration 3060 -3.1473743125857023\n",
      "fitness at iteration 3070 -3.1473743125857023\n",
      "fitness at iteration 3080 -3.1473743125857023\n",
      "fitness at iteration 3090 -3.1473743125857023\n",
      "fitness at iteration 3100 -3.1473743125857023\n",
      "fitness at iteration 3110 -3.1473743125857023\n",
      "fitness at iteration 3120 -3.1473743125857023\n",
      "fitness at iteration 3130 -3.1473743125857023\n",
      "fitness at iteration 3140 -3.1473743125857023\n",
      "fitness at iteration 3150 -3.1473743125857023\n",
      "fitness at iteration 3160 -3.1473743125857023\n",
      "fitness at iteration 3170 -3.1473743125857023\n",
      "fitness at iteration 3180 -3.1473743125857023\n",
      "fitness at iteration 3190 -3.1473743125857023\n",
      "fitness at iteration 3200 -3.1473743125857023\n",
      "fitness at iteration 3210 -3.1473743125857023\n",
      "fitness at iteration 3220 -3.1473743125857023\n",
      "fitness at iteration 3230 -3.1473743125857023\n",
      "fitness at iteration 3240 -3.1473743125857023\n",
      "fitness at iteration 3250 -3.1473743125857023\n",
      "fitness at iteration 3260 -3.1473743125857023\n",
      "fitness at iteration 3270 -3.1473743125857023\n",
      "fitness at iteration 3280 -3.1473743125857023\n",
      "fitness at iteration 3290 -3.1473743125857023\n",
      "fitness at iteration 3300 -3.1473743125857023\n",
      "fitness at iteration 3310 -3.1473743125857023\n",
      "fitness at iteration 3320 -3.1473743125857023\n",
      "fitness at iteration 3330 -3.1473743125857023\n",
      "fitness at iteration 3340 -3.1473743125857023\n",
      "fitness at iteration 3350 -3.1473743125857023\n",
      "fitness at iteration 3360 -3.1473743125857023\n",
      "fitness at iteration 3370 -3.1473743125857023\n",
      "fitness at iteration 3380 -3.1473743125857023\n",
      "fitness at iteration 3390 -3.1473743125857023\n",
      "fitness at iteration 3400 -3.1473743125857023\n",
      "fitness at iteration 3410 -3.1473743125857023\n",
      "fitness at iteration 3420 -3.1473743125857023\n",
      "fitness at iteration 3430 -3.1473743125857023\n",
      "fitness at iteration 3440 -3.1473743125857023\n",
      "fitness at iteration 3450 -3.1473743125857023\n",
      "fitness at iteration 3460 -3.1473743125857023\n",
      "fitness at iteration 3470 -3.1473743125857023\n",
      "fitness at iteration 3480 -3.1473743125857023\n",
      "fitness at iteration 3490 -3.1473743125857023\n",
      "fitness at iteration 3500 -3.1473743125857023\n",
      "fitness at iteration 3510 -3.1473743125857023\n",
      "fitness at iteration 3520 -3.1473743125857023\n",
      "fitness at iteration 3530 -3.1473743125857023\n",
      "fitness at iteration 3540 -3.1473743125857023\n",
      "fitness at iteration 3550 -3.1473743125857023\n",
      "fitness at iteration 3560 -3.1473743125857023\n",
      "fitness at iteration 3570 -3.1473743125857023\n",
      "fitness at iteration 3580 -3.1473743125857023\n",
      "fitness at iteration 3590 -3.1473743125857023\n",
      "fitness at iteration 3600 -3.1473743125857023\n",
      "fitness at iteration 3610 -3.1473743125857023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitness at iteration 3620 -3.1473743125857023\n",
      "fitness at iteration 3630 -3.1473743125857023\n",
      "fitness at iteration 3640 -3.1473743125857023\n",
      "fitness at iteration 3650 -3.1473743125857023\n",
      "fitness at iteration 3660 -3.1473743125857023\n",
      "fitness at iteration 3670 -3.1473743125857023\n",
      "fitness at iteration 3680 -3.1473743125857023\n",
      "fitness at iteration 3690 -3.1473743125857023\n",
      "fitness at iteration 3700 -3.1473743125857023\n",
      "fitness at iteration 3710 -3.1473743125857023\n",
      "fitness at iteration 3720 -3.1473743125857023\n",
      "fitness at iteration 3730 -3.1473743125857023\n",
      "fitness at iteration 3740 -3.1473743125857023\n",
      "fitness at iteration 3750 -3.1473743125857023\n",
      "fitness at iteration 3760 -3.1473743125857023\n",
      "fitness at iteration 3770 -3.1473743125857023\n",
      "fitness at iteration 3780 -3.1473743125857023\n",
      "fitness at iteration 3790 -3.1473743125857023\n",
      "fitness at iteration 3800 -3.1473743125857023\n",
      "fitness at iteration 3810 -3.1473743125857023\n",
      "fitness at iteration 3820 -3.1473743125857023\n",
      "fitness at iteration 3830 -3.1473743125857023\n",
      "fitness at iteration 3840 -3.1473743125857023\n",
      "fitness at iteration 3850 -3.1473743125857023\n",
      "fitness at iteration 3860 -3.1473743125857023\n",
      "fitness at iteration 3870 -3.1473743125857023\n",
      "fitness at iteration 3880 -3.1473743125857023\n",
      "fitness at iteration 3890 -3.1473743125857023\n",
      "fitness at iteration 3900 -3.1473743125857023\n",
      "fitness at iteration 3910 -3.1473743125857023\n",
      "fitness at iteration 3920 -3.1473743125857023\n",
      "fitness at iteration 3930 -3.1473743125857023\n",
      "fitness at iteration 3940 -3.1473743125857023\n",
      "fitness at iteration 3950 -3.1473743125857023\n",
      "fitness at iteration 3960 -3.1473743125857023\n",
      "fitness at iteration 3970 -3.1473743125857023\n",
      "fitness at iteration 3980 -3.1473743125857023\n",
      "fitness at iteration 3990 -3.1473743125857023\n",
      "fitness at iteration 4000 -3.1473743125857023\n",
      "local optimum discovered by solver:\n",
      " [ 1.58611855e+00 -2.84133778e+00  1.54509570e+00  1.77184867e-01\n",
      " -2.63893109e+00 -4.32382694e-01 -9.64783944e-01 -1.66447279e+00\n",
      "  1.07640820e-01 -1.45649965e+00  1.01200684e-01 -4.84555317e-01\n",
      "  1.89273366e-01 -1.92959756e-01  1.46657174e+00 -2.87442570e-01\n",
      "  4.55844704e-01 -1.75954759e+00 -1.72389613e+00 -3.03575399e-02\n",
      " -1.48116602e-01  2.08118587e-01 -3.38758850e-01 -5.09136077e-01\n",
      "  1.71455680e-01 -3.12639984e+00  5.41245658e+00  3.00504417e-02\n",
      " -9.99424805e-01 -8.43966507e-01 -4.23151075e+00 -8.06970230e-01\n",
      "  3.44111480e-01 -3.89656221e+00 -1.07200696e+00 -8.72276715e-01\n",
      "  1.55086752e+00 -9.78212761e-01  2.08877634e+00 -7.52348746e-01\n",
      " -1.55775500e+00 -2.94293786e-01 -6.36998202e-01 -1.08231122e+00\n",
      " -2.56845363e+00  1.69928915e-01 -1.78152892e-01 -1.02605140e+00\n",
      "  6.45432297e-01  6.70965593e-01  1.99253523e+00 -6.33874643e-01\n",
      "  6.60166852e-01 -8.27814505e-01 -1.93078143e+00  1.73999425e-01\n",
      " -5.01508464e-01 -6.03335894e-01 -1.33308335e+00  1.10983948e-01\n",
      "  1.48378476e+00  1.78477700e+00  9.22932057e-01  3.29263780e-01\n",
      "  4.27254389e-01  5.86382035e-01  6.50999143e-01  2.26006726e-01\n",
      "  4.18176085e-01  1.08365794e+00  2.17443329e-02 -1.88429688e+00\n",
      "  3.08062428e-01  3.32631033e-02  2.17078948e+00  5.36315722e-02\n",
      " -5.03214281e-01 -1.13582056e+00  8.73243689e-01 -1.02872782e+00\n",
      "  1.22988160e-01 -4.55743413e-01 -3.21660100e-01 -5.24934957e-03\n",
      "  1.14863715e+00 -6.76992318e-01  1.36950047e+00 -7.28295083e-01\n",
      "  1.64410684e-01 -4.38948527e-01  2.34064352e-01 -9.52301352e-01\n",
      " -2.96412424e+00 -1.88608106e-01 -9.29738033e-02 -2.32574349e+00\n",
      "  1.30820687e+00 -1.34877698e+00  1.31574113e+00 -1.04744678e+00\n",
      "  7.01200159e-01 -4.37771508e-01 -1.51148601e+00 -1.72000385e+00\n",
      " -4.85586241e-01  1.17717305e+00 -1.90180495e+00 -5.41740146e-01\n",
      " -2.78118273e+00  4.03836688e-01  1.93625511e+00 -4.43286950e+00\n",
      " -2.35039384e+00 -3.88814630e+00 -4.50581672e+00 -3.89880169e+00\n",
      " -3.72980199e+00 -2.46755512e+00 -3.01270877e+00 -4.22007506e+00\n",
      " -5.06677396e+00  1.17612502e+00  5.12775091e+00 -8.29718016e+00\n",
      " -7.54109355e+00 -6.61253559e+00 -7.98820519e+00 -7.14896563e+00\n",
      " -5.84875324e+00 -6.20365068e+00 -8.37513929e+00 -7.48264312e+00\n",
      "  7.00371393e-01 -1.11172615e+00  2.06614307e+00  8.12323270e-01\n",
      "  1.61149189e-02  1.59099025e-01 -5.08008429e-01 -7.39485952e-01\n",
      " -4.76334224e-01  5.47691713e-01 -1.91736482e-01 -4.74379263e-01\n",
      "  1.91599587e+00  1.66547700e+00  2.93838554e+00  1.22441774e+00\n",
      "  9.76329855e-01 -8.69393449e-01  4.23572783e-01 -1.06816625e+00\n",
      "  7.33016788e-01  1.17722214e+00 -1.94231777e+00 -7.69385596e-01\n",
      "  1.03738139e+00 -1.66386272e+00  3.23828373e+00  5.29049894e-02\n",
      " -4.97753229e-01 -1.26846229e+00 -4.11624339e-01 -8.42033688e-01\n",
      " -5.67931242e-01 -9.98002993e-03 -1.05523942e+00  1.01049555e-01\n",
      "  1.23303219e-01 -3.17695748e+00  2.30413895e+00 -2.51822507e+00\n",
      "  3.47950326e-02 -1.54220728e+00 -1.19085684e+00 -2.03645720e+00\n",
      " -2.94229625e-01 -3.81633348e-01 -1.22476405e+00 -2.09524392e+00\n",
      "  7.48019053e-02  8.35923997e-01  1.42551619e+00 -3.35162672e+00\n",
      " -1.46349141e+00 -1.28469691e+00 -9.90635568e-01 -2.20239893e+00\n",
      " -3.00844235e+00  5.45662697e-02 -2.28503273e+00 -2.18446933e+00\n",
      "  1.39421836e+00 -1.99553358e+00  3.32218920e+00 -2.99422778e+00\n",
      " -3.29725670e-02 -7.58889993e-02 -2.13954594e+00  1.30253315e-01\n",
      "  8.78832124e-01  1.21163230e+00 -2.09923694e+00  1.88380670e-01\n",
      "  8.86485679e-01 -3.85214311e+00 -4.30962122e-01  6.06025611e-01\n",
      " -1.03531876e+00  6.30763132e-02  6.31246483e-01 -1.22026755e-01\n",
      " -4.41465328e-01  1.10996139e+00  4.41338692e-01  1.25939162e-01\n",
      "  1.15040100e+00  2.65961914e-01  1.78315569e+00 -1.07075684e+00\n",
      " -1.65940821e+00 -1.24577070e+00 -3.15785993e-01 -1.84133910e+00\n",
      "  3.47869701e-01 -3.42815660e-01 -4.99532674e-01  6.75278280e-01\n",
      "  1.11088049e+00 -8.87020414e-01  1.94844458e+00 -1.71861275e+00\n",
      "  7.49128207e-01 -2.11952702e+00  5.22872861e-01  7.68217068e-01\n",
      "  6.17299176e-02  6.21628933e-01  6.03479887e-01 -1.10836931e-01\n",
      "  2.28147524e+00  6.60610268e+00  5.96531210e+00  5.51310295e+00\n",
      "  1.75486553e+00  2.44112012e+00  6.12536133e+00  2.88236642e+00\n",
      "  3.94246526e+00  6.43146499e+00  9.88685455e+00  3.98245597e+00\n",
      "  2.99439107e+00  4.88148753e+00  6.74728336e+00  5.25334850e+00\n",
      "  5.73989388e+00  2.45930141e+00  2.40655862e+00  2.35247921e+00\n",
      " -3.66096680e+00 -4.28814387e+00 -6.04192829e+00 -5.34295355e+00\n",
      " -4.10215000e+00  1.78727387e+00 -4.50474094e+00 -4.24942918e+00\n",
      " -3.92070724e+00 -9.43408547e+00 -9.77934760e+00 -3.23125716e+00\n",
      " -6.87395959e-01 -5.44291832e+00 -8.01202973e+00 -7.46004762e+00\n",
      " -3.65691052e+00 -3.24168828e+00 -3.92492093e+00 -6.56548248e-01\n",
      "  1.47858600e+00  1.24346050e-01 -4.26582113e+00 -3.20479565e+00\n",
      " -1.96010845e+00  1.64614942e+00 -8.11673159e-01  3.82816595e+00\n",
      " -5.85688774e-01 -3.60152908e+00 -6.85821281e+00 -8.92562950e-01\n",
      "  7.76866706e-01 -1.04563011e+00 -3.60879066e+00 -2.84180597e+00\n",
      " -3.49715912e+00 -2.19045727e+00 -4.22852746e+00  2.09357016e+00\n",
      " -2.37926159e+00 -2.10953755e+00 -3.29240447e+00  1.32627337e+00\n",
      " -3.21244091e+00 -1.68910943e+00  2.99524786e-01 -3.76526204e+00\n",
      " -2.16108398e+00 -4.86095256e+00 -6.39310305e+00 -3.19815711e+00\n",
      " -3.44315855e+00  4.29975584e+00 -2.28062698e+00 -2.88759096e+00\n",
      " -1.51786971e+00 -6.52977145e-01 -9.40286813e-01 -2.01768774e+00\n",
      " -2.18336783e+00 -2.95934882e+00 -4.71403064e+00 -2.98300185e+00\n",
      " -3.84101894e+00  2.16980028e+00  1.32847250e+00 -2.67095713e+00\n",
      " -3.50703744e+00 -3.61083458e+00 -6.40871435e+00 -2.60671787e+00\n",
      " -3.33767947e+00  1.67643892e+00 -4.73642352e+00 -1.60585669e+00\n",
      " -1.10527216e+00 -7.27852866e-01 -2.61425212e+00 -3.61746214e+00\n",
      " -1.99590212e+00 -3.37729910e+00 -5.32709403e-01 -1.01652770e+00\n",
      " -1.89606249e+00 -2.55100072e+00 -2.62212503e+00 -2.08227939e+00\n",
      " -3.04009600e+00 -3.73390281e+00 -5.35799748e+00 -3.11091725e+00\n",
      " -2.39660453e+00 -1.21208779e+00 -2.41561136e+00 -3.99677357e+00\n",
      " -2.24047454e-01 -2.99690197e-01 -3.52448961e+00 -3.45493009e+00\n",
      " -1.98524503e+00 -3.03766432e+00 -2.87215152e+00 -1.87018573e+00\n",
      " -8.98087641e-01 -3.18825110e-01 -6.05973884e-01  1.99449001e+00\n",
      " -4.20279209e+00 -4.00806603e+00 -5.39521618e+00  3.90252532e+00\n",
      " -3.05000841e+00 -8.41928391e-02 -2.59559907e+00 -2.38643182e+00\n",
      " -4.29409949e+00 -7.02304829e-01 -1.70993483e+00  8.03132059e-02\n",
      " -2.55796079e+00 -2.49411376e+00 -3.55013680e+00 -5.19194056e+00\n",
      " -1.80566860e+00 -3.52303621e-01  2.41553848e-01  1.81939560e+00\n",
      " -3.74477761e+00 -4.15759395e+00 -6.62114995e+00  2.72609474e+00\n",
      " -1.02008792e+00 -2.91187016e+00 -3.31313683e+00 -2.88357602e+00\n",
      " -5.71762173e-01  1.85811995e+00 -2.57289241e+00 -3.62227140e+00\n",
      " -2.50300529e+00 -2.56440733e+00 -4.52701179e+00 -2.87136245e+00\n",
      " -3.38994336e+00 -5.94021829e-02 -1.46199663e+00 -3.29857378e+00\n",
      " -3.29138269e+00 -4.95170264e+00 -6.19223447e+00 -6.50750524e-01\n",
      " -2.09421281e+00  4.17569718e-01 -2.96906647e+00 -3.46193731e+00\n",
      "  1.74355486e+00 -8.45571935e-01 -3.23655880e+00  2.51027323e+00\n",
      " -1.95353630e-02 -2.08639066e+00 -2.79761096e+00  1.98739998e+00\n",
      " -2.27500839e+00 -6.05592972e-01 -2.92060975e+00 -2.52312407e+00\n",
      "  4.41625498e+00 -5.24031806e+00 -6.49790532e+00 -3.98764075e-01\n",
      " -3.10872236e+00 -6.01140012e-01 -7.63551575e-01 -3.03530846e+00\n",
      " -1.13528391e-01  1.74715604e+00  1.23936117e+00 -3.37135710e-01\n",
      " -1.21074822e+00  4.64614635e+00 -1.51032399e-02 -2.50129761e+00\n",
      " -2.12633131e+00 -2.57534764e+00 -3.68005480e+00 -4.67964872e+00\n",
      " -3.12065241e+00 -3.73727096e+00 -5.88821376e+00 -3.94860171e-01\n",
      " -3.07056243e+00  5.17597992e-01 -2.97931423e+00 -1.68286142e+00\n",
      " -2.14087984e+00 -1.85770344e+00 -2.80805687e+00 -2.59003241e+00]\n",
      "fitness score at this local optimum: -3.1473743125857023\n"
     ]
    }
   ],
   "source": [
    "# defines PEPG (NES) solver\n",
    "pepg = PEPG(NPARAMS,                         # number of model parameters\n",
    "            sigma_init=0.5,                  # initial standard deviation\n",
    "            learning_rate=0.1,               # learning rate for standard deviation\n",
    "            learning_rate_decay=1.0,       # don't anneal the learning rate\n",
    "            popsize=NPOPULATION,             # population size\n",
    "            average_baseline=False,          # set baseline to average of batch\n",
    "            weight_decay=0.00,            # weight decay coefficient\n",
    "            rank_fitness=False,           # use rank rather than fitness numbers\n",
    "            forget_best=False)   \n",
    "pepg_history = test_solver(pepg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = ga.ask()\n",
    "evluate_func(model, solutions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = model.forward(np.ones([1,12]))\n",
    "#model.forward(X[0])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([20, 12]), array([20, 20]), array([11, 20])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lyr_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ARC]",
   "language": "python",
   "name": "conda-env-ARC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
